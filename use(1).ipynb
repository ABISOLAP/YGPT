{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fa032160",
      "metadata": {
        "id": "fa032160"
      },
      "source": [
        "# In this notebook, I'll try to apply TRANSFORMER model for a CHATBOT from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "698a1320",
      "metadata": {
        "id": "698a1320"
      },
      "source": [
        "## Overview\n",
        "***\n",
        "*A chatbot or chatterbot is a software application used to conduct an on-line chat conversation via text or text-to-speech, in lieu of providing direct contact with a live human agent chatbot is a type of software that can help human by automating conversations and interact with them through messaging platforms. here are different approaches and tools that you can use when building chatbots. Depending on the use case you want to address, some technologies are more appropriate than others. Combining artificial intelligence forms such as natural language processing, machine learning, and semantic understanding may be the best option to achieve the desired results.*\n",
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b94feefe",
      "metadata": {
        "id": "b94feefe"
      },
      "source": [
        "## How to build a Chatbot for our task?\n",
        "***\n",
        "ChatBots are usually Task specific means if there a chatbot which serves only food delivery app have trained on a dataset which\n",
        "completely different from the dataset on which chatbot which serves online healthcare app. Similary, for this kaggle problem\n",
        "we have provided with movie dataset which may feel that its not specific to any task, but actually it is specific to how people\n",
        "will interect generally as these movie dialogues are nothing but daily life conversation between people however, that chatbot\n",
        "may reply things which sounds too much dramatic and filmy like some dialogue of Tom cruise, shah rukh khan etc.\n",
        "\n",
        "We can approch this problem by applying Neural network models like encoder-decoder architecture with some attention mechanism.\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "425a8749",
      "metadata": {
        "id": "425a8749"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import numpy as np\n",
        "import codecs\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import ast\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# import seaborn as sns\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import re\n",
        "import warnings\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import joblib\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import Progbar\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "#file_path = 'https://docs.google.com/spreadsheets/d/12oPDLqEbwcCN1bhzfFIAkOFRU0Vqf7xY/export?format=xlsx'\n",
        "file_path = 'https://docs.google.com/spreadsheets/d/1R7kmn9LtcGZFUCplZVN804NXsGWyUBHF/export?format=xlsx'  # Update this path to the location of your uploaded file\n",
        "sheet_name = 'combinedata'\n",
        "\n",
        "# Read the specific sheet into a DataFrame\n",
        "data = pd.read_excel(file_path, sheet_name=sheet_name)\n",
        "\n",
        "# Display the DataFrame\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CjCc4-MK551M",
        "outputId": "45661003-f91c-4365-e7ac-2404ee46cb8d"
      },
      "id": "CjCc4-MK551M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       question  \\\n",
              "0            Ẹ ǹlẹ́ o, Ẹlẹ́ran.   \n",
              "1               Ṣé ajé ń wọgbá?   \n",
              "2           Eélòó ni kilo ẹran?   \n",
              "3         Ṣé jálẹ̀jálẹ̀ nì yẹn?   \n",
              "4  Ṣe bí o ti mọ, ẹlẹ́wà Ṣàpọn.   \n",
              "\n",
              "                                              answer  \n",
              "0                                Ẹ ǹlẹ́ o, Oníbàárà.  \n",
              "1                                        Olúwa ṣeun.  \n",
              "2                                   N1, 300 ni kílò.  \n",
              "3  Bẹ́ẹ̀ni, jálẹ̀jálẹ̀ nì yẹn. Kódà, àwọn kan ń t...  \n",
              "4                                        Òótó lẹ sọ.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-821511ee-5f69-4b4c-96fb-3f9d72863603\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ẹ ǹlẹ́ o, Ẹlẹ́ran.</td>\n",
              "      <td>Ẹ ǹlẹ́ o, Oníbàárà.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ṣé ajé ń wọgbá?</td>\n",
              "      <td>Olúwa ṣeun.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Eélòó ni kilo ẹran?</td>\n",
              "      <td>N1, 300 ni kílò.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ṣé jálẹ̀jálẹ̀ nì yẹn?</td>\n",
              "      <td>Bẹ́ẹ̀ni, jálẹ̀jálẹ̀ nì yẹn. Kódà, àwọn kan ń t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ṣe bí o ti mọ, ẹlẹ́wà Ṣàpọn.</td>\n",
              "      <td>Òótó lẹ sọ.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-821511ee-5f69-4b4c-96fb-3f9d72863603')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-821511ee-5f69-4b4c-96fb-3f9d72863603 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-821511ee-5f69-4b4c-96fb-3f9d72863603');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-83f26618-e02e-4b19-ae8e-307f3d3202fd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83f26618-e02e-4b19-ae8e-307f3d3202fd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-83f26618-e02e-4b19-ae8e-307f3d3202fd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1229,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 748,\n        \"samples\": [\n          \" Gbow\\u00f3 re\\u0323\",\n          \"\\u1eb8 k\\u00fa is\\u1eb9\\u0301 o. B\\u00e1wo ni?\",\n          \"\\u00d3 d\\u00e1a. \\u00c0b\\u00f9s\\u00ed Ol\\u00fawa o. \\u1eb8 gba ow\\u00f3.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 693,\n        \"samples\": [\n          \" M\\u00e0\\u00e1 t\\u00e0 \\u00e1 f\\u00fan un y\\u00edn n\\u00ed  \\u1ecdg\\u1ecd\\u0301\\u1ecd\\u0300ru\\u0300n-\\u00fan m\\u00e9j\\u00ec l\\u00e9l\\u00e0\\u00e1d\\u1ecd\\u0301rin \\u1eb9gb\\u1eb9\\u0300run\",\n          \"\\u1eccg\\u1ecd\\u0301r\\u00f9n-\\u00fan m\\u00e9j\\u00ec \\u00e0ti \\u00e0\\u00e1d\\u1ecd\\u0301ta n\\u00e1\\u00edr\\u00e0\",\n          \"\\u1eb8 \\u1e63\\u00e9 o. \\u1eb8 gba \\u1e63\\u1eb9\\u0301\\u0144j\\u00ec y\\u00edn\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HYQKhupr56eI"
      },
      "id": "HYQKhupr56eI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ea97982f",
      "metadata": {
        "id": "ea97982f"
      },
      "source": [
        "## Loading cleaned data that I have preprared while EDA and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0645f4e",
      "metadata": {
        "id": "c0645f4e"
      },
      "outputs": [],
      "source": [
        "#data = joblib.load('data_cleaned')\n",
        "#data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81af0edc",
      "metadata": {
        "id": "81af0edc"
      },
      "source": [
        "## Dividing into TWO, train/validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d494f32",
      "metadata": {
        "id": "5d494f32"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, validation = train_test_split(data, test_size=0.2, random_state=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebf65780",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebf65780",
        "outputId": "1cf1256b-b455-4264-ac93-f5bcc458c7f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab_size_ans, vocab_size_ques:1458,1370\n"
          ]
        }
      ],
      "source": [
        "vocab_ans = list(set(\" \".join(train['answer'].values).split()))\n",
        "vocab_ques = list(set(\" \".join(train['question'].values).split()))\n",
        "vocab_size_ans, vocab_size_ques = len(vocab_ans), len(vocab_ques)\n",
        "print(f\"vocab_size_ans, vocab_size_ques:{vocab_size_ans},{ vocab_size_ques}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "289182c9",
      "metadata": {
        "id": "289182c9"
      },
      "source": [
        "## Using tfds SubwordTextEncoder, it will create tokens\n",
        "#### example Multiplication -> Multi, pli, cat, i, on\n",
        "#### Advantages:\n",
        "    1. Reduces vocab size => faster learning\n",
        "    2. Reduces chances of missing word in test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f322ecb3",
      "metadata": {
        "id": "f322ecb3"
      },
      "outputs": [],
      "source": [
        "tokenizer_a = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    train['answer'], target_vocab_size=2**15)\n",
        "\n",
        "tokenizer_q = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    train['question'], target_vocab_size=2**15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "609b2718",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "609b2718",
        "outputId": "06423e5c-86ed-4c9e-fbd6-81f1990b5697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer_q:1499\n",
            "tokenizer_a:1594\n"
          ]
        }
      ],
      "source": [
        "print(f\"tokenizer_q:{tokenizer_q.vocab_size}\")\n",
        "print(f\"tokenizer_a:{tokenizer_a.vocab_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02392cc3",
      "metadata": {
        "id": "02392cc3"
      },
      "source": [
        "#### Examples of subword tokenization in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf67e110",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf67e110",
        "outputId": "d680aeb6-f061-4dac-b014-ab32e75b114c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized string is [1407, 1448, 1437, 1449, 1438, 1439, 1452, 1370, 1438, 1439, 1437, 1449, 1438, 1439, 1452]\n",
            "The original string: Encoder decoder\n",
            "1407---->E\n",
            "1448---->n\n",
            "1437---->c\n",
            "1449---->o\n",
            "1438---->d\n",
            "1439---->e\n",
            "1452---->r\n",
            "1370----> \n",
            "1438---->d\n",
            "1439---->e\n",
            "1437---->c\n",
            "1449---->o\n",
            "1438---->d\n",
            "1439---->e\n",
            "1452---->r\n",
            "================================================================================\n",
            "Tokenized string is [1312, 1353, 1342, 1354, 1343, 1344, 1357, 1275, 1343, 1344, 1342, 1354, 1343, 1344, 1357]\n",
            "The original string: Encoder decoder\n",
            "1312---->E\n",
            "1353---->n\n",
            "1342---->c\n",
            "1354---->o\n",
            "1343---->d\n",
            "1344---->e\n",
            "1357---->r\n",
            "1275----> \n",
            "1343---->d\n",
            "1344---->e\n",
            "1342---->c\n",
            "1354---->o\n",
            "1343---->d\n",
            "1344---->e\n",
            "1357---->r\n"
          ]
        }
      ],
      "source": [
        "sample_string = 'Encoder decoder'\n",
        "\n",
        "tokenized_string = tokenizer_a.encode(sample_string)\n",
        "print ('Tokenized string is {}'.format(tokenized_string))\n",
        "\n",
        "original_string = tokenizer_a.decode(tokenized_string)\n",
        "print ('The original string: {}'.format(original_string))\n",
        "\n",
        "for token in tokenized_string:\n",
        "    print(str(token) + \"---->\" + tokenizer_a.decode([token]))\n",
        "\n",
        "print(\"=\"*80)\n",
        "tokenized_string = tokenizer_q.encode(sample_string)\n",
        "print ('Tokenized string is {}'.format(tokenized_string))\n",
        "\n",
        "original_string = tokenizer_q.decode(tokenized_string)\n",
        "print ('The original string: {}'.format(original_string))\n",
        "\n",
        "for token in tokenized_string:\n",
        "    print(str(token) + \"---->\" + tokenizer_q.decode([token]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff9e30ce",
      "metadata": {
        "id": "ff9e30ce"
      },
      "source": [
        "###### 0-27512 for questions\n",
        "\n",
        "###### 0-27357 for answers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d9469ee",
      "metadata": {
        "id": "3d9469ee"
      },
      "source": [
        "* **Attaching token number '27513' representing \\<start> and '27514' representing \\<end> QUESTIONS**\n",
        "* **Attaching token number '27358' representing \\<start> and '27359' representing \\<end> ANSWERS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeb6d990",
      "metadata": {
        "id": "aeb6d990"
      },
      "outputs": [],
      "source": [
        "def encode(ques, ans):\n",
        "    ques = [tokenizer_q.vocab_size] + tokenizer_q.encode(ques.numpy()) + [tokenizer_q.vocab_size+1]\n",
        "    ans = [tokenizer_a.vocab_size] + tokenizer_a.encode(ans.numpy()) + [tokenizer_a.vocab_size+1]\n",
        "    return ques, ans\n",
        "\n",
        "def tf_encode(ques, ans):\n",
        "    result_ques, result_ans = tf.py_function(encode, [ques, ans], [tf.float32, tf.float32])\n",
        "    result_ques.set_shape([None])\n",
        "    result_ans.set_shape([None])\n",
        "    return result_ques, result_ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc78baed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc78baed",
        "outputId": "2594af67-a5a4-4601-9ecd-edca0fb7a692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Fun mi ni meta kilo. \n",
            "  O dara, o jẹ ẹgbẹrun meji ati ọgọrun naira.\n",
            "tf.Tensor(\n",
            "[1.499e+03 1.275e+03 6.300e+01 1.200e+01 1.000e+00 6.160e+02 6.370e+02\n",
            " 1.289e+03 1.500e+03], shape=(9,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[1594. 1370.    8.   45.    2.   42.   17.   15.   81.   73.   47.   12.\n",
            " 1384. 1595.], shape=(14,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(train['question'].values[0],\"\\n\",train['answer'].values[0])\n",
        "question, answer = tf_encode(train['question'].values[0],train['answer'].values[0])\n",
        "print(question)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1413123",
      "metadata": {
        "id": "d1413123"
      },
      "source": [
        "### Creating train_dataset/test_dataset object from Dataframe + padding\n",
        "\n",
        "###### prefetch: If I'm at epoch-20 then prefetch prepares the Batch for epoch-21, so when epoch-21 start, it will make available the batch in no time, basically enhancing speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54bb56c4",
      "metadata": {
        "id": "54bb56c4"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(dict(train))\n",
        "train_dataset = train_dataset.map(lambda x:tf_encode(x['question'], x['answer']))\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(20000).padded_batch(64, padded_shapes=([None],[None]))\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "436c73c8",
      "metadata": {
        "id": "436c73c8"
      },
      "outputs": [],
      "source": [
        "val_dataset = tf.data.Dataset.from_tensor_slices(dict(validation))\n",
        "val_dataset = val_dataset.map(lambda x:tf_encode(x['question'], x['answer']))\n",
        "val_dataset = val_dataset.padded_batch(64, padded_shapes=([None],[None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85844a50",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85844a50",
        "outputId": "24764adb-6688-45a8-fa12-87ae99cc3a00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 95), dtype=float32, numpy=\n",
              "array([[1499.,   10.,   62., ...,    0.,    0.,    0.],\n",
              "       [1499.,  460.,   37., ...,    0.,    0.,    0.],\n",
              "       [1499., 1275.,   21., ...,    0.,    0.,    0.],\n",
              "       ...,\n",
              "       [1499., 1275.,    9., ...,    0.,    0.,    0.],\n",
              "       [1499.,   15.,   27., ...,    0.,    0.,    0.],\n",
              "       [1499., 1275.,  848., ...,   20., 1289., 1500.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "question, answer = next(iter(train_dataset))\n",
        "question"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80bf8241",
      "metadata": {
        "id": "80bf8241"
      },
      "source": [
        "### Positional encoding function where 'i' -> embedding dimn index, 'pos' -> word index in a sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9500b25e",
      "metadata": {
        "id": "9500b25e"
      },
      "source": [
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ae35c9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "2ae35c9d",
        "outputId": "5b89fdcd-eb87-4a95-a503-f34f3f5db95a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 50, 512)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Positional encoding\n",
        "\n",
        "\n",
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis,:]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "\n",
        "pos_encoding = positional_encoding(50, 512)\n",
        "print (pos_encoding.shape)\n",
        "\n",
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d393354",
      "metadata": {
        "id": "5d393354"
      },
      "source": [
        "## 1. Pad Masking\n",
        "#### Making all the padded tokens, self attention/attention calculation of a word with those paddings will be ignored"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ecbd402",
      "metadata": {
        "id": "9ecbd402"
      },
      "source": [
        "\n",
        "* Here output dimn -> (batch_size, 1, 1, seq_len)\n",
        "          \n",
        "*  for each 8 attention heads, for each query word it will be multiplied, thats why creating 1, 1 in the middle\n",
        "\n",
        "##### (batch_size, 8, query_word_len, seq_len) * (batch_size, 1, 1, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "628afe59",
      "metadata": {
        "id": "628afe59"
      },
      "outputs": [],
      "source": [
        "# Masking\n",
        "\n",
        "'''Mask all the pad tokens in the batch of sequence.\n",
        "It ensures that the model does not treat padding as the input.\n",
        "The mask indicates where pad value 0 is present: it outputs a 1 at those locations, and a 0 otherwise.\n",
        "'''\n",
        "def create_padding_mask(seq):\n",
        "    \"\"\"\n",
        "    seq: padded sentence length (5)\n",
        "    \"\"\"\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    # Adding 2, 3 dimn using tf.newaxis, 2-> As this mask will be multiplied with each attention head and 3-> for each word in a sentance\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "# create_padding_mask(np.array([[1,2,3,0,0,0],[1,2,3,0,0,1]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d9aceca",
      "metadata": {
        "id": "2d9aceca"
      },
      "source": [
        "## 2. Looakahead mask\n",
        "\n",
        "for the first word, its self attention calculation with be ignored with proceeding words i.e. second, third word and so on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d26dea25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d26dea25",
        "outputId": "8665a2ce-f233-4c46-8f30-0739d5be0662"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[0., 1., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# Looakahead mask\n",
        "\n",
        "\"\"\"The look-ahead mask is used to mask the future tokens in a sequence.\n",
        "In other words, the mask indicates which entries should not be used.\n",
        "\"\"\"\n",
        "def create_look_ahead_mask(size):\n",
        "    \"\"\"\n",
        "    The look-ahead mask is used to mask the future tokens in a sequence\n",
        "    \"\"\"\n",
        "    #band_part with this setting creates lower triangular matrix that's why subtracting from 1\n",
        "    # [[0., 1., 1.],\n",
        "    #  [0., 0., 1.],\n",
        "    #  [0., 0., 0.]] output with size:3\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask  # (seq_len, seq_len)\n",
        "\n",
        "#example\n",
        "x = tf.random.uniform((1, 3))\n",
        "temp = create_look_ahead_mask(x.shape[1])\n",
        "temp"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2896ca7e",
      "metadata": {
        "id": "2896ca7e"
      },
      "source": [
        "## 3. SELF-ATTENTION calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04daf49a",
      "metadata": {
        "id": "04daf49a"
      },
      "source": [
        "![image](images/attenion_formula.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f55e44a8",
      "metadata": {
        "id": "f55e44a8"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    q: query shape == (..., seq_len_q, depth) # NOTE: depth=dk\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "    output, attention_weights\n",
        "    \"\"\"\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "    # scale matmul_qk. underroot d_model i.e. underroot(100)\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  # -1e9 ~ (-INFINITY) => where ever mask is set, make its logit value close to -INF\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores add up to 1.\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "    return output, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "798eca41",
      "metadata": {
        "id": "798eca41"
      },
      "source": [
        "## 4. MultiHeadAttention Calculation\n",
        "#### Its nothing but a RESHAPING !! :)\n",
        "example :\n",
        "1. if we have (64, 10, 512)->(BATCH, #words, embeddding) as input, after passiing it though dense layer of size 512 we will get (64, 10, 512)\n",
        "2. We have three such dense layers representing/for Q, K, V encodings.\n",
        "3. (64, 10, 512) -> reshape -> (64, 8, 10 ,64) -> (BATCH, attention head, #words, encode)\n",
        "    '64' is representing encoding of 512 -> 64 dimension\n",
        "4. (64, 8, 10 ,64)->self-attention-code->(64, 8, 10 ,10) called attention weights, (64, 8, 10 ,64)\n",
        "5. Concatenate such that 8*64 will be new dimension -> (64, 10, 512)\n",
        "    \n",
        "    **Beware embedding dimn must be divisible by no. of heads and always embedding_dimn/heads => encodin_dimn(here 64)**\n",
        "    \n",
        "    **NICE HACK** (-_-)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f41cf3c",
      "metadata": {
        "id": "0f41cf3c"
      },
      "source": [
        "![image](images/multi_head.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab0b6ec3",
      "metadata": {
        "id": "ab0b6ec3"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model  # typically 512\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "809f3721",
      "metadata": {
        "id": "809f3721"
      },
      "source": [
        "## 5. ENCODER layer\n",
        "\n",
        "#### -> self Multihead attention -> Residual+Norm -> Feed forward neural network -> Residual+Norm\n",
        "\n",
        "![image](images/encoder_layer.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c9b69f5",
      "metadata": {
        "id": "2c9b69f5"
      },
      "outputs": [],
      "source": [
        "def point_wise_feed_forward_network(d_model, dff): #dff = 512\n",
        "    return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "    ])\n",
        "\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model) # with Attention\n",
        "\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model) #with Attention\n",
        "\n",
        "        return out2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d18de1ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d18de1ef",
        "outputId": "c3810c4c-7ac4-46fe-8bfb-7a86a974130f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 43, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((64, 43, 512)), False, None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d49552e",
      "metadata": {
        "id": "0d49552e"
      },
      "source": [
        "## 6. DECODER LAYER\n",
        "#### -> self multihead attention -> residual+norm -> multihead attention(between E & D) -> residual+norm -> feed forward NN -> residual+norm\n",
        "\n",
        "![image](images/decoder_layer.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3061bff",
      "metadata": {
        "id": "f3061bff"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "        attn2, attn_weights_block2 = self.mha2(\n",
        "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a2123ca",
      "metadata": {
        "id": "7a2123ca"
      },
      "source": [
        "## 7. ENCODER\n",
        "#### Nothing but repetation of Encoder layer :-) + Input embedding vector + positional encoding\n",
        "\n",
        "![image](images/encoder.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98960a2d",
      "metadata": {
        "id": "98960a2d"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                                self.d_model)\n",
        "\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                           for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]   #x:(batch, seq_len)\n",
        "        # adding embedding and position encoding.\n",
        "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fd0dcc2",
      "metadata": {
        "id": "5fd0dcc2"
      },
      "source": [
        "## 8. DECODER\n",
        "#### Nothing but Repetation of decoder layers + posisional encoder + embedding layer\n",
        "\n",
        "![image](images/decoder.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4232ef9",
      "metadata": {
        "id": "b4232ef9"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                           for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                                 look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "        # x.shape == (batch_size, target_seq_len, d_model)\n",
        "        return x, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50318f4f",
      "metadata": {
        "id": "50318f4f"
      },
      "source": [
        "## 9. TRANSFORMER\n",
        "\n",
        "#### Nothing but encoder+decoder+dense layer\n",
        "##### (64,10,512) -> dense_layer -> (64,10,vocab_size)\n",
        "\n",
        "![image](images/transformer.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ba6c5e1",
      "metadata": {
        "id": "6ba6c5e1"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                               input_vocab_size, pe_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                               target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inp, tar, training, enc_padding_mask,\n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "        dec_output, attention_weights = self.decoder(\n",
        "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "        return final_output, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db99e050",
      "metadata": {
        "id": "db99e050"
      },
      "source": [
        "#### So to create a transformer architecture which is now everywhere in NLP models, we require only 9 STEPs :-O"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ad95ab6",
      "metadata": {
        "id": "0ad95ab6"
      },
      "outputs": [],
      "source": [
        "# tokenizer_a = joblib.load(\"tokenizer_a\")\n",
        "# tokenizer_q = joblib.load(\"tokenizer_q\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca0583e3",
      "metadata": {
        "id": "ca0583e3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb699bbb",
      "metadata": {
        "id": "fb699bbb"
      },
      "outputs": [],
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = tokenizer_q.vocab_size + 2\n",
        "target_vocab_size = tokenizer_a.vocab_size + 2\n",
        "dropout_rate = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6dd6833",
      "metadata": {
        "id": "a6dd6833"
      },
      "source": [
        "## Custom learning rate, proposed in the paper\n",
        "#### First learning rate will be high and then after some epochs it will be decreasing ONLY\n",
        "\n",
        "![image](images/lr.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af0bd674",
      "metadata": {
        "id": "af0bd674"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model,tf.float32) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95ed1f98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "95ed1f98",
        "outputId": "19ed0e4d-75eb-459a-872d-ef0fa00b9a2f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Value for attr 'T' of int64 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Rsqrt}}; Op<name=Rsqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Rsqrt] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-f16deb2bf343>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomSchedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m optimizer = tf.keras.optimizers.Adam(learning_rate,  beta_1=0.9, beta_2=0.98,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                      epsilon=1e-9)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, name, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         )\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36m_build_learning_rate\u001b[0;34m(self, learning_rate)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mesh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;31m# For DTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36m_build_learning_rate\u001b[0;34m(self, learning_rate)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;31m# Create a variable to hold the current learning rate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 current_learning_rate = tf.convert_to_tensor(\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 )\n\u001b[1;32m    387\u001b[0m                 self._current_learning_rate = tf.Variable(\n",
            "\u001b[0;32m<ipython-input-61-44e69433fbf9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0marg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarmup_steps\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5882\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5883\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Value for attr 'T' of int64 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Rsqrt}}; Op<name=Rsqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Rsqrt] name: "
          ]
        }
      ],
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate,  beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8e3f318",
      "metadata": {
        "id": "a8e3f318"
      },
      "source": [
        "### See, increasing and then decreasing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a02400de",
      "metadata": {
        "id": "a02400de",
        "outputId": "739860cb-a876-4e1e-c3e2-e6665533006a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "execution_count": 356,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05c461fb",
      "metadata": {
        "id": "05c461fb"
      },
      "source": [
        "##### Custom losss function, same as sparse categorical cross entropy but considers only no padded values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba02438a",
      "metadata": {
        "id": "ba02438a"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01b9a90f",
      "metadata": {
        "id": "01b9a90f"
      },
      "source": [
        "### Creating pad mask(encoder), pad mask(decoder), lookahead mask(decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b61f4e3f",
      "metadata": {
        "id": "b61f4e3f"
      },
      "outputs": [],
      "source": [
        "def create_masks(inp, tar):\n",
        "    # Encoder padding mask\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 2nd attention block in the decoder.\n",
        "    # This padding mask is used to mask the encoder outputs.\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 1st attention block in the decoder.\n",
        "    # It is used to pad and mask future tokens in the input received by\n",
        "    # the decoder.\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "644505ce",
      "metadata": {
        "id": "644505ce"
      },
      "source": [
        "## Saving model checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a9ba0f8",
      "metadata": {
        "id": "7a9ba0f8"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"./checkpoints_test/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print ('Latest checkpoint restored!!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4c3cdf4",
      "metadata": {
        "id": "f4c3cdf4"
      },
      "source": [
        "## Using gradient tape for getting derivatives of loss functions w.r.t. weights then applyiing to optimizer => BACKPROPAGATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e0dc634",
      "metadata": {
        "id": "5e0dc634"
      },
      "outputs": [],
      "source": [
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(inp, tar_inp,\n",
        "                                     True,\n",
        "                                     enc_padding_mask,\n",
        "                                     combined_mask,\n",
        "                                     dec_padding_mask)\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(tar_real, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf410f58",
      "metadata": {
        "id": "bf410f58"
      },
      "source": [
        "## Creating sample transformer to know the no. of trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d0ea48",
      "metadata": {
        "id": "d0d0ea48",
        "outputId": "7bec5f23-c310-4329-e5b9-c8c0f357bc45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_5 (Encoder)         multiple                  4315008   \n",
            "                                                                 \n",
            " decoder_5 (Decoder)         multiple                  4560384   \n",
            "                                                                 \n",
            " dense_293 (Dense)           multiple                  3529440   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,404,832\n",
            "Trainable params: 12,404,832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "input_vocab_size = tokenizer_q.vocab_size + 2\n",
        "target_vocab_size = tokenizer_a.vocab_size + 2\n",
        "dropout_rate = 0.1\n",
        "\n",
        "sample_transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size,\n",
        "                          pe_input=input_vocab_size,\n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)\n",
        "\n",
        "temp_input = tf.random.uniform((64, 27), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_target = tf.random.uniform((64, 27), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "fn_out, _ = sample_transformer(temp_input, temp_target, training=False,\n",
        "                               enc_padding_mask=None,\n",
        "                               look_ahead_mask=None,\n",
        "                               dec_padding_mask=None)\n",
        "\n",
        "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "sample_transformer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d653136",
      "metadata": {
        "id": "8d653136"
      },
      "outputs": [],
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "input_vocab_size = tokenizer_q.vocab_size + 2\n",
        "target_vocab_size = tokenizer_a.vocab_size + 2\n",
        "dropout_rate = 0.1\n",
        "\n",
        "\n",
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size,\n",
        "                          pe_input=input_vocab_size,\n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a47d4b94",
      "metadata": {
        "id": "a47d4b94",
        "outputId": "0ca1ed7e-e86f-4be4-d62d-a1c5f339457c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1/20\n",
            "111552/111527 [==============================] - 304s 3ms/step - loss: 5.6714 - acc: 0.0692\n",
            "\n",
            "epoch 2/20\n",
            "111552/111527 [==============================] - 219s 2ms/step - loss: 5.5175 - acc: 0.0746\n",
            "\n",
            "epoch 3/20\n",
            "111552/111527 [==============================] - 157s 1ms/step - loss: 5.4285 - acc: 0.0776\n",
            "\n",
            "epoch 4/20\n",
            "111552/111527 [==============================] - 155s 1ms/step - loss: 5.3675 - acc: 0.0797\n",
            "\n",
            "epoch 5/20\n",
            "111552/111527 [==============================] - 156s 1ms/step - loss: 5.3132 - acc: 0.0813\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/train\\ckpt-1\n",
            "\n",
            "epoch 6/20\n",
            "111552/111527 [==============================] - 157s 1ms/step - loss: 5.2668 - acc: 0.0827\n",
            "\n",
            "epoch 7/20\n",
            "111552/111527 [==============================] - 157s 1ms/step - loss: 5.2267 - acc: 0.0840\n",
            "\n",
            "epoch 8/20\n",
            "111552/111527 [==============================] - 157s 1ms/step - loss: 5.1926 - acc: 0.0851\n",
            "\n",
            "epoch 9/20\n",
            "111552/111527 [==============================] - 157s 1ms/step - loss: 5.1626 - acc: 0.0863\n",
            "\n",
            "epoch 10/20\n",
            "111552/111527 [==============================] - 157s 1ms/step - loss: 5.1361 - acc: 0.0873\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/train\\ckpt-2\n",
            "\n",
            "epoch 11/20\n",
            "111552/111527 [==============================] - 157s 1ms/step - loss: 5.1137 - acc: 0.0883\n",
            "\n",
            "epoch 12/20\n",
            "111552/111527 [==============================] - 154s 1ms/step - loss: 5.0942 - acc: 0.0891\n",
            "\n",
            "epoch 13/20\n",
            "111552/111527 [==============================] - 155s 1ms/step - loss: 5.0781 - acc: 0.0898\n",
            "\n",
            "epoch 14/20\n",
            "111552/111527 [==============================] - 154s 1ms/step - loss: 5.0637 - acc: 0.0904\n",
            "\n",
            "epoch 15/20\n",
            "111552/111527 [==============================] - 155s 1ms/step - loss: 5.0511 - acc: 0.0910\n",
            "Saving checkpoint for epoch 15 at ./checkpoints/train\\ckpt-3\n",
            "\n",
            "epoch 16/20\n",
            "111552/111527 [==============================] - 157s 1ms/step - loss: 5.0399 - acc: 0.0916\n",
            "\n",
            "epoch 17/20\n",
            "111552/111527 [==============================] - 157s 1ms/step - loss: 5.0301 - acc: 0.0921\n",
            "\n",
            "epoch 18/20\n",
            "111552/111527 [==============================] - 157s 1ms/step - loss: 5.0213 - acc: 0.0925\n",
            "\n",
            "epoch 19/20\n",
            "111552/111527 [==============================] - 156s 1ms/step - loss: 5.0136 - acc: 0.0930\n",
            "\n",
            "epoch 20/20\n",
            "111552/111527 [==============================] - 158s 1ms/step - loss: 5.0065 - acc: 0.0934\n",
            "Saving checkpoint for epoch 20 at ./checkpoints/train\\ckpt-4\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "batch_size = 64\n",
        "metrics_names = ['loss', 'acc']\n",
        "train_loss.reset_states()\n",
        "train_accuracy.reset_states()\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
        "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
        "\n",
        "    # inp -> question, tar -> answer\n",
        "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
        "\n",
        "        pb_i.add(batch_size, values=values)\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "addc165f",
      "metadata": {
        "id": "addc165f",
        "outputId": "20ce1e37-d25a-4019-ac30-357639cd751b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1/5\n",
            "111552/111527 [==============================] - 169s 2ms/step - loss: 4.9995 - acc: 0.0938\n",
            "\n",
            "epoch 2/5\n",
            "111552/111527 [==============================] - 154s 1ms/step - loss: 4.9930 - acc: 0.0941\n",
            "\n",
            "epoch 3/5\n",
            "111552/111527 [==============================] - 215s 2ms/step - loss: 4.9866 - acc: 0.0945\n",
            "\n",
            "epoch 4/5\n",
            "111552/111527 [==============================] - 489s 4ms/step - loss: 4.9803 - acc: 0.0948\n",
            "\n",
            "epoch 5/5\n",
            "111552/111527 [==============================] - 487s 4ms/step - loss: 4.9743 - acc: 0.0951\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/train\\ckpt-5\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 5\n",
        "batch_size = 64\n",
        "metrics_names = ['loss', 'acc']\n",
        "# train_loss.reset_states()\n",
        "# train_accuracy.reset_states()\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
        "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
        "\n",
        "    # inp -> question, tar -> answer\n",
        "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
        "\n",
        "        pb_i.add(batch_size, values=values)\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca700ca",
      "metadata": {
        "id": "eca700ca"
      },
      "source": [
        "# With those hyperparameters it seems model is not learning at all, as there is no progress in 25 EPOCHS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c6542bc",
      "metadata": {
        "id": "3c6542bc"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 27\n",
        "def evaluate(inp_sentence):\n",
        "    start_token = [tokenizer_q.vocab_size]\n",
        "    end_token = [tokenizer_q.vocab_size + 1]\n",
        "\n",
        "    # inp sentence is portuguese, hence adding the start and end token\n",
        "    inp_sentence = start_token + tokenizer_q.encode(inp_sentence) + end_token\n",
        "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "\n",
        "    # as the target is english, the first word to the transformer should be the\n",
        "    # english start token.\n",
        "    decoder_input = [tokenizer_a.vocab_size]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "    for i in range(MAX_LENGTH):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "            encoder_input, output)\n",
        "\n",
        "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "        predictions, attention_weights = transformer(encoder_input,\n",
        "                                                     output,\n",
        "                                                     False,\n",
        "                                                     enc_padding_mask,\n",
        "                                                     combined_mask,\n",
        "                                                     dec_padding_mask)\n",
        "\n",
        "        # select the last word from the seq_len dimension\n",
        "#         print(predictions.shape,\"aa\",predictions[: ,-1:, :].shape)\n",
        "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "#         print(predicted_id, output)\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "        if predicted_id == tokenizer_a.vocab_size+1:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0), attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcfbf0c7",
      "metadata": {
        "id": "dcfbf0c7"
      },
      "outputs": [],
      "source": [
        "inp_sentence = \"i am doing great\"\n",
        "a, b = evaluate(inp_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30d36412",
      "metadata": {
        "id": "30d36412"
      },
      "source": [
        "# RESULTS are ABSURD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ee9871b",
      "metadata": {
        "id": "7ee9871b",
        "outputId": "c5aeedf2-2e9e-47a4-994f-57dd908fee89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "thel\n",
            "thel\n",
            "thel\n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n",
            "luc \n"
          ]
        }
      ],
      "source": [
        "for i in a[1:]:\n",
        "    print(tokenizer_a.decode([i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c45aebc4",
      "metadata": {
        "id": "c45aebc4"
      },
      "source": [
        " ## Lets try with different hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a79abb08",
      "metadata": {
        "id": "a79abb08",
        "outputId": "ed315b6c-4548-4ac0-8a5d-270ebe96cdac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_5 (Encoder)         multiple                  4315008   \n",
            "                                                                 \n",
            " decoder_5 (Decoder)         multiple                  4560384   \n",
            "                                                                 \n",
            " dense_293 (Dense)           multiple                  3529440   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,404,832\n",
            "Trainable params: 12,404,832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = tokenizer_q.vocab_size + 2\n",
        "target_vocab_size = tokenizer_a.vocab_size + 2\n",
        "dropout_rate = 0.1\n",
        "temp_input = tf.random.uniform((64, 27), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_target = tf.random.uniform((64, 27), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "fn_out, _ = sample_transformer(temp_input, temp_target, training=False,\n",
        "                               enc_padding_mask=None,\n",
        "                               look_ahead_mask=None,\n",
        "                               dec_padding_mask=None)\n",
        "\n",
        "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "sample_transformer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5709905a",
      "metadata": {
        "id": "5709905a",
        "outputId": "ed632b49-5998-4424-ab0e-25c34a0cb01d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_6 (Encoder)         multiple                  8098048   \n",
            "                                                                 \n",
            " decoder_6 (Decoder)         multiple                  8585728   \n",
            "                                                                 \n",
            " dense_326 (Dense)           multiple                  7031520   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,715,296\n",
            "Trainable params: 23,715,296\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_layers = 2\n",
        "d_model = 256\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "input_vocab_size = tokenizer_q.vocab_size + 2\n",
        "target_vocab_size = tokenizer_a.vocab_size + 2\n",
        "dropout_rate = 0.1\n",
        "\n",
        "sample_transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size,\n",
        "                          pe_input=input_vocab_size,\n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)\n",
        "\n",
        "temp_input = tf.random.uniform((64, 27), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_target = tf.random.uniform((64, 27), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "fn_out, _ = sample_transformer(temp_input, temp_target, training=False,\n",
        "                               enc_padding_mask=None,\n",
        "                               look_ahead_mask=None,\n",
        "                               dec_padding_mask=None)\n",
        "sample_transformer.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17f5656e",
      "metadata": {
        "id": "17f5656e"
      },
      "source": [
        "### Now the trainable parameters has increased from 12M to 24M, Lets test this!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27d76c6e",
      "metadata": {
        "id": "27d76c6e",
        "outputId": "e50e8e49-33a6-4e88-d2b1-9367ad6eef4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1/20\n",
            "111552/111527 [==============================] - 184s 2ms/step - loss: 5.2070 - acc: 0.0921\n",
            "\n",
            "epoch 2/20\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 4.9807 - acc: 0.0979\n",
            "\n",
            "epoch 3/20\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 4.8595 - acc: 0.1010\n",
            "\n",
            "epoch 4/20\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 4.7736 - acc: 0.1033\n",
            "\n",
            "epoch 5/20\n",
            "111552/111527 [==============================] - 145s 1ms/step - loss: 4.7041 - acc: 0.1053\n",
            "Saving checkpoint for epoch 5 at ./checkpoints2/train\\ckpt-1\n",
            "\n",
            "epoch 6/20\n",
            "111552/111527 [==============================] - 144s 1ms/step - loss: 4.6442 - acc: 0.1072\n",
            "\n",
            "epoch 7/20\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 4.5910 - acc: 0.1089\n",
            "\n",
            "epoch 8/20\n",
            "111552/111527 [==============================] - 145s 1ms/step - loss: 4.5422 - acc: 0.1107\n",
            "\n",
            "epoch 9/20\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 4.4968 - acc: 0.1123\n",
            "\n",
            "epoch 10/20\n",
            "111552/111527 [==============================] - 145s 1ms/step - loss: 4.4542 - acc: 0.1139\n",
            "Saving checkpoint for epoch 10 at ./checkpoints2/train\\ckpt-2\n",
            "\n",
            "epoch 11/20\n",
            "111552/111527 [==============================] - 148s 1ms/step - loss: 4.4140 - acc: 0.1155\n",
            "\n",
            "epoch 12/20\n",
            "111552/111527 [==============================] - 144s 1ms/step - loss: 4.3760 - acc: 0.1171\n",
            "\n",
            "epoch 13/20\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 4.3402 - acc: 0.1186\n",
            "\n",
            "epoch 14/20\n",
            "111552/111527 [==============================] - 145s 1ms/step - loss: 4.3065 - acc: 0.1201\n",
            "\n",
            "epoch 15/20\n",
            "111552/111527 [==============================] - 145s 1ms/step - loss: 4.2753 - acc: 0.1216\n",
            "Saving checkpoint for epoch 15 at ./checkpoints2/train\\ckpt-3\n",
            "\n",
            "epoch 16/20\n",
            "111552/111527 [==============================] - 146s 1ms/step - loss: 4.2467 - acc: 0.1230\n",
            "\n",
            "epoch 17/20\n",
            "111552/111527 [==============================] - 144s 1ms/step - loss: 4.2203 - acc: 0.1245\n",
            "\n",
            "epoch 18/20\n",
            "111552/111527 [==============================] - 144s 1ms/step - loss: 4.1958 - acc: 0.1258\n",
            "\n",
            "epoch 19/20\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 4.1724 - acc: 0.1271\n",
            "\n",
            "epoch 20/20\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 4.1498 - acc: 0.1285\n",
            "Saving checkpoint for epoch 20 at ./checkpoints2/train\\ckpt-4\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "batch_size = 64\n",
        "metrics_names = ['loss', 'acc']\n",
        "train_loss.reset_states()\n",
        "train_accuracy.reset_states()\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
        "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
        "\n",
        "    # inp -> question, tar -> answer\n",
        "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
        "\n",
        "        pb_i.add(batch_size, values=values)\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8990f5ec",
      "metadata": {
        "id": "8990f5ec",
        "outputId": "64487a12-6fd3-4290-8f16-9bf0f1c1055e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 1/30\n",
            "111552/111527 [==============================] - 146s 1ms/step - loss: 4.1279 - acc: 0.1297\n",
            "\n",
            "epoch 2/30\n",
            "111552/111527 [==============================] - 148s 1ms/step - loss: 4.1067 - acc: 0.1310\n",
            "\n",
            "epoch 3/30\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 4.0860 - acc: 0.1322\n",
            "\n",
            "epoch 4/30\n",
            "111552/111527 [==============================] - 144s 1ms/step - loss: 4.0660 - acc: 0.1334\n",
            "\n",
            "epoch 5/30\n",
            "111552/111527 [==============================] - 146s 1ms/step - loss: 4.0465 - acc: 0.1346\n",
            "Saving checkpoint for epoch 5 at ./checkpoints2/train\\ckpt-5\n",
            "\n",
            "epoch 6/30\n",
            "111552/111527 [==============================] - 147s 1ms/step - loss: 4.0276 - acc: 0.1358\n",
            "\n",
            "epoch 7/30\n",
            "111552/111527 [==============================] - 149s 1ms/step - loss: 4.0091 - acc: 0.1369\n",
            "\n",
            "epoch 8/30\n",
            "111552/111527 [==============================] - 149s 1ms/step - loss: 3.9912 - acc: 0.1381\n",
            "\n",
            "epoch 9/30\n",
            "111552/111527 [==============================] - 147s 1ms/step - loss: 3.9736 - acc: 0.1392\n",
            "\n",
            "epoch 10/30\n",
            "111552/111527 [==============================] - 148s 1ms/step - loss: 3.9566 - acc: 0.1402\n",
            "Saving checkpoint for epoch 10 at ./checkpoints2/train\\ckpt-6\n",
            "\n",
            "epoch 11/30\n",
            "111552/111527 [==============================] - 148s 1ms/step - loss: 3.9399 - acc: 0.1413\n",
            "\n",
            "epoch 12/30\n",
            "111552/111527 [==============================] - 148s 1ms/step - loss: 3.9237 - acc: 0.1423\n",
            "\n",
            "epoch 13/30\n",
            "111552/111527 [==============================] - 148s 1ms/step - loss: 3.9078 - acc: 0.1434\n",
            "\n",
            "epoch 14/30\n",
            "111552/111527 [==============================] - 149s 1ms/step - loss: 3.8923 - acc: 0.1444\n",
            "\n",
            "epoch 15/30\n",
            "111552/111527 [==============================] - 149s 1ms/step - loss: 3.8773 - acc: 0.1453\n",
            "Saving checkpoint for epoch 15 at ./checkpoints2/train\\ckpt-7\n",
            "\n",
            "epoch 16/30\n",
            "111552/111527 [==============================] - 149s 1ms/step - loss: 3.8624 - acc: 0.1463\n",
            "\n",
            "epoch 17/30\n",
            "111552/111527 [==============================] - 148s 1ms/step - loss: 3.8478 - acc: 0.1473\n",
            "\n",
            "epoch 18/30\n",
            "111552/111527 [==============================] - 151s 1ms/step - loss: 3.8336 - acc: 0.1482\n",
            "\n",
            "epoch 19/30\n",
            "111552/111527 [==============================] - 153s 1ms/step - loss: 3.8196 - acc: 0.1491\n",
            "\n",
            "epoch 20/30\n",
            "111552/111527 [==============================] - 151s 1ms/step - loss: 3.8059 - acc: 0.1500\n",
            "Saving checkpoint for epoch 20 at ./checkpoints2/train\\ckpt-8\n",
            "\n",
            "epoch 21/30\n",
            "111552/111527 [==============================] - 151s 1ms/step - loss: 3.7925 - acc: 0.1509\n",
            "\n",
            "epoch 22/30\n",
            "111552/111527 [==============================] - 153s 1ms/step - loss: 3.7793 - acc: 0.1518\n",
            "\n",
            "epoch 23/30\n",
            "111552/111527 [==============================] - 150s 1ms/step - loss: 3.7663 - acc: 0.1526\n",
            "\n",
            "epoch 24/30\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.7536 - acc: 0.1534\n",
            "\n",
            "epoch 25/30\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.7411 - acc: 0.1543\n",
            "Saving checkpoint for epoch 25 at ./checkpoints2/train\\ckpt-9\n",
            "\n",
            "epoch 26/30\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.7288 - acc: 0.1551\n",
            "\n",
            "epoch 27/30\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 3.7167 - acc: 0.1559\n",
            "\n",
            "epoch 28/30\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.7048 - acc: 0.1567\n",
            "\n",
            "epoch 29/30\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.6931 - acc: 0.1574\n",
            "\n",
            "epoch 30/30\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.6816 - acc: 0.1582\n",
            "Saving checkpoint for epoch 30 at ./checkpoints2/train\\ckpt-10\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 30\n",
        "batch_size = 64\n",
        "metrics_names = ['loss', 'acc']\n",
        "# train_loss.reset_states()\n",
        "# train_accuracy.reset_states()\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
        "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
        "\n",
        "    # inp -> question, tar -> answer\n",
        "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
        "\n",
        "        pb_i.add(batch_size, values=values)\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e364afa5",
      "metadata": {
        "id": "e364afa5"
      },
      "source": [
        "## Learning is slow, but not stagnant (-__-)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47943fa8",
      "metadata": {
        "id": "47943fa8",
        "outputId": "bdd9520a-6675-4d35-ddd5-71a37a9ca97a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 51/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.6703 - acc: 0.1589\n",
            "\n",
            "epoch 52/100\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.6591 - acc: 0.1597\n",
            "\n",
            "epoch 53/100\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 3.6481 - acc: 0.1604\n",
            "\n",
            "epoch 54/100\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 3.6373 - acc: 0.1611\n",
            "\n",
            "epoch 55/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.6266 - acc: 0.1618\n",
            "Saving checkpoint for epoch 55 at ./checkpoints2/train\\ckpt-11\n",
            "\n",
            "epoch 56/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.6161 - acc: 0.1625\n",
            "\n",
            "epoch 57/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.6057 - acc: 0.1632\n",
            "\n",
            "epoch 58/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.5955 - acc: 0.1639\n",
            "\n",
            "epoch 59/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.5855 - acc: 0.1646\n",
            "\n",
            "epoch 60/100\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 3.5755 - acc: 0.1652\n",
            "Saving checkpoint for epoch 60 at ./checkpoints2/train\\ckpt-12\n",
            "\n",
            "epoch 61/100\n",
            "111552/111527 [==============================] - 144s 1ms/step - loss: 3.5657 - acc: 0.1659\n",
            "\n",
            "epoch 62/100\n",
            "111552/111527 [==============================] - 144s 1ms/step - loss: 3.5561 - acc: 0.1665\n",
            "\n",
            "epoch 63/100\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 3.5465 - acc: 0.1671\n",
            "\n",
            "epoch 64/100\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 3.5371 - acc: 0.1678\n",
            "\n",
            "epoch 65/100\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 3.5278 - acc: 0.1684\n",
            "Saving checkpoint for epoch 65 at ./checkpoints2/train\\ckpt-13\n",
            "\n",
            "epoch 66/100\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.5186 - acc: 0.1690\n",
            "\n",
            "epoch 67/100\n",
            "111552/111527 [==============================] - 265s 2ms/step - loss: 3.5094 - acc: 0.1696\n",
            "\n",
            "epoch 68/100\n",
            "111552/111527 [==============================] - 364s 3ms/step - loss: 3.5004 - acc: 0.1702\n",
            "\n",
            "epoch 69/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.4914 - acc: 0.1708\n",
            "\n",
            "epoch 70/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.4825 - acc: 0.1714\n",
            "Saving checkpoint for epoch 70 at ./checkpoints2/train\\ckpt-14\n",
            "\n",
            "epoch 71/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.4737 - acc: 0.1719\n",
            "\n",
            "epoch 72/100\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 3.4650 - acc: 0.1725\n",
            "\n",
            "epoch 73/100\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 3.4564 - acc: 0.1730\n",
            "\n",
            "epoch 74/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.4479 - acc: 0.1736\n",
            "\n",
            "epoch 75/100\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 3.4394 - acc: 0.1741\n",
            "Saving checkpoint for epoch 75 at ./checkpoints2/train\\ckpt-15\n",
            "\n",
            "epoch 76/100\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 3.4311 - acc: 0.1747\n",
            "\n",
            "epoch 77/100\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 3.4229 - acc: 0.1752\n",
            "\n",
            "epoch 78/100\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.4148 - acc: 0.1757\n",
            "\n",
            "epoch 79/100\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.4068 - acc: 0.1762\n",
            "\n",
            "epoch 80/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3989 - acc: 0.1768\n",
            "Saving checkpoint for epoch 80 at ./checkpoints2/train\\ckpt-16\n",
            "\n",
            "epoch 81/100\n",
            "111552/111527 [==============================] - 140s 1ms/step - loss: 3.3912 - acc: 0.1773\n",
            "\n",
            "epoch 82/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3837 - acc: 0.1778\n",
            "\n",
            "epoch 83/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3762 - acc: 0.1783\n",
            "\n",
            "epoch 84/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3689 - acc: 0.1787\n",
            "\n",
            "epoch 85/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3617 - acc: 0.1792\n",
            "Saving checkpoint for epoch 85 at ./checkpoints2/train\\ckpt-17\n",
            "\n",
            "epoch 86/100\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.3546 - acc: 0.1797\n",
            "\n",
            "epoch 87/100\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.3476 - acc: 0.1802\n",
            "\n",
            "epoch 88/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3407 - acc: 0.1807\n",
            "\n",
            "epoch 89/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3339 - acc: 0.1811\n",
            "\n",
            "epoch 90/100\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.3273 - acc: 0.1816\n",
            "Saving checkpoint for epoch 90 at ./checkpoints2/train\\ckpt-18\n",
            "\n",
            "epoch 91/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3206 - acc: 0.1820\n",
            "\n",
            "epoch 92/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3141 - acc: 0.1825\n",
            "\n",
            "epoch 93/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3077 - acc: 0.1829\n",
            "\n",
            "epoch 94/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3012 - acc: 0.1834\n",
            "\n",
            "epoch 95/100\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2949 - acc: 0.1838\n",
            "Saving checkpoint for epoch 95 at ./checkpoints2/train\\ckpt-19\n",
            "\n",
            "epoch 96/100\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2886 - acc: 0.1843\n",
            "\n",
            "epoch 97/100\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2824 - acc: 0.1847\n",
            "\n",
            "epoch 98/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.2763 - acc: 0.1851\n",
            "\n",
            "epoch 99/100\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2702 - acc: 0.1855\n",
            "\n",
            "epoch 100/100\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.2642 - acc: 0.1860\n",
            "Saving checkpoint for epoch 100 at ./checkpoints2/train\\ckpt-20\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 100\n",
        "batch_size = 64\n",
        "metrics_names = ['loss', 'acc']\n",
        "# train_loss.reset_states()\n",
        "# train_accuracy.reset_states()\n",
        "for epoch in range(50, EPOCHS):\n",
        "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
        "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
        "\n",
        "    # inp -> question, tar -> answer\n",
        "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
        "\n",
        "        pb_i.add(batch_size, values=values)\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c533244c",
      "metadata": {
        "id": "c533244c",
        "outputId": "ada9ceb8-fb46-4535-c825-f69ffaa7dc82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 101/150\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2584 - acc: 0.1864\n",
            "\n",
            "epoch 102/150\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2525 - acc: 0.1868\n",
            "\n",
            "epoch 103/150\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2468 - acc: 0.1872\n",
            "\n",
            "epoch 104/150\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2411 - acc: 0.1876\n",
            "\n",
            "epoch 105/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.2355 - acc: 0.1880\n",
            "Saving checkpoint for epoch 105 at ./checkpoints2/train\\ckpt-21\n",
            "\n",
            "epoch 106/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.2300 - acc: 0.1884\n",
            "\n",
            "epoch 107/150\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2245 - acc: 0.1888\n",
            "\n",
            "epoch 108/150\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 3.2192 - acc: 0.1892\n",
            "\n",
            "epoch 109/150\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 3.2139 - acc: 0.1895\n",
            "\n",
            "epoch 110/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.2086 - acc: 0.1899\n",
            "Saving checkpoint for epoch 110 at ./checkpoints2/train\\ckpt-22\n",
            "\n",
            "epoch 111/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.2034 - acc: 0.1903\n",
            "\n",
            "epoch 112/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1983 - acc: 0.1907\n",
            "\n",
            "epoch 113/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1932 - acc: 0.1910\n",
            "\n",
            "epoch 114/150\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.1881 - acc: 0.1914\n",
            "\n",
            "epoch 115/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1831 - acc: 0.1918\n",
            "Saving checkpoint for epoch 115 at ./checkpoints2/train\\ckpt-23\n",
            "\n",
            "epoch 116/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1781 - acc: 0.1921\n",
            "\n",
            "epoch 117/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1732 - acc: 0.1925\n",
            "\n",
            "epoch 118/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1683 - acc: 0.1928\n",
            "\n",
            "epoch 119/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1634 - acc: 0.1932\n",
            "\n",
            "epoch 120/150\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 3.1586 - acc: 0.1936\n",
            "Saving checkpoint for epoch 120 at ./checkpoints2/train\\ckpt-24\n",
            "\n",
            "epoch 121/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1538 - acc: 0.1939\n",
            "\n",
            "epoch 122/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1490 - acc: 0.1942\n",
            "\n",
            "epoch 123/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1442 - acc: 0.1946\n",
            "\n",
            "epoch 124/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1395 - acc: 0.1949\n",
            "\n",
            "epoch 125/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1348 - acc: 0.1953\n",
            "Saving checkpoint for epoch 125 at ./checkpoints2/train\\ckpt-25\n",
            "\n",
            "epoch 126/150\n",
            "111552/111527 [==============================] - 144s 1ms/step - loss: 3.1301 - acc: 0.1956\n",
            "\n",
            "epoch 127/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1255 - acc: 0.1960\n",
            "\n",
            "epoch 128/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1209 - acc: 0.1963\n",
            "\n",
            "epoch 129/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1163 - acc: 0.1966\n",
            "\n",
            "epoch 130/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1118 - acc: 0.1969\n",
            "Saving checkpoint for epoch 130 at ./checkpoints2/train\\ckpt-26\n",
            "\n",
            "epoch 131/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1072 - acc: 0.1973\n",
            "\n",
            "epoch 132/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1027 - acc: 0.1976\n",
            "\n",
            "epoch 133/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0983 - acc: 0.1979\n",
            "\n",
            "epoch 134/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0938 - acc: 0.1982\n",
            "\n",
            "epoch 135/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0894 - acc: 0.1986\n",
            "Saving checkpoint for epoch 135 at ./checkpoints2/train\\ckpt-27\n",
            "\n",
            "epoch 136/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0850 - acc: 0.1989\n",
            "\n",
            "epoch 137/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0806 - acc: 0.1992\n",
            "\n",
            "epoch 138/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0763 - acc: 0.1995\n",
            "\n",
            "epoch 139/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0720 - acc: 0.1998\n",
            "\n",
            "epoch 140/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0677 - acc: 0.2001\n",
            "Saving checkpoint for epoch 140 at ./checkpoints2/train\\ckpt-28\n",
            "\n",
            "epoch 141/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0635 - acc: 0.2004\n",
            "\n",
            "epoch 142/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0593 - acc: 0.2007\n",
            "\n",
            "epoch 143/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0550 - acc: 0.2010\n",
            "\n",
            "epoch 144/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0509 - acc: 0.2013\n",
            "\n",
            "epoch 145/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0467 - acc: 0.2016\n",
            "Saving checkpoint for epoch 145 at ./checkpoints2/train\\ckpt-29\n",
            "\n",
            "epoch 146/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0426 - acc: 0.2019\n",
            "\n",
            "epoch 147/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0385 - acc: 0.2022\n",
            "\n",
            "epoch 148/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0344 - acc: 0.2025\n",
            "\n",
            "epoch 149/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0304 - acc: 0.2028\n",
            "\n",
            "epoch 150/150\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0263 - acc: 0.2031\n",
            "Saving checkpoint for epoch 150 at ./checkpoints2/train\\ckpt-30\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 150\n",
        "batch_size = 64\n",
        "metrics_names = ['loss', 'acc']\n",
        "# train_loss.reset_states()\n",
        "# train_accuracy.reset_states()\n",
        "for epoch in range(100, EPOCHS):\n",
        "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
        "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
        "\n",
        "    # inp -> question, tar -> answer\n",
        "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
        "\n",
        "        pb_i.add(batch_size, values=values)\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ebb9b2d",
      "metadata": {
        "id": "7ebb9b2d",
        "outputId": "49db7083-347e-4b36-b53d-9520ddfa3294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 151/200\n",
            "111552/111527 [==============================] - 140s 1ms/step - loss: 3.0223 - acc: 0.2033\n",
            "\n",
            "epoch 152/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.0183 - acc: 0.2036\n",
            "\n",
            "epoch 153/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.0144 - acc: 0.2039\n",
            "\n",
            "epoch 154/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.0105 - acc: 0.2042\n",
            "\n",
            "epoch 155/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.0066 - acc: 0.2045\n",
            "Saving checkpoint for epoch 155 at ./checkpoints2/train\\ckpt-31\n",
            "\n",
            "epoch 156/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 3.0027 - acc: 0.2047\n",
            "\n",
            "epoch 157/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.9989 - acc: 0.2050\n",
            "\n",
            "epoch 158/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9950 - acc: 0.2053\n",
            "\n",
            "epoch 159/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9912 - acc: 0.2056\n",
            "\n",
            "epoch 160/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9875 - acc: 0.2058\n",
            "Saving checkpoint for epoch 160 at ./checkpoints2/train\\ckpt-32\n",
            "\n",
            "epoch 161/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9837 - acc: 0.2061\n",
            "\n",
            "epoch 162/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.9800 - acc: 0.2063\n",
            "\n",
            "epoch 163/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9763 - acc: 0.2066\n",
            "\n",
            "epoch 164/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9726 - acc: 0.2069\n",
            "\n",
            "epoch 165/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9689 - acc: 0.2071\n",
            "Saving checkpoint for epoch 165 at ./checkpoints2/train\\ckpt-33\n",
            "\n",
            "epoch 166/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9653 - acc: 0.2074\n",
            "\n",
            "epoch 167/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9617 - acc: 0.2077\n",
            "\n",
            "epoch 168/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.9581 - acc: 0.2079\n",
            "\n",
            "epoch 169/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9546 - acc: 0.2082\n",
            "\n",
            "epoch 170/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.9510 - acc: 0.2084\n",
            "Saving checkpoint for epoch 170 at ./checkpoints2/train\\ckpt-34\n",
            "\n",
            "epoch 171/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9475 - acc: 0.2087\n",
            "\n",
            "epoch 172/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.9440 - acc: 0.2089\n",
            "\n",
            "epoch 173/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.9406 - acc: 0.2092\n",
            "\n",
            "epoch 174/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.9371 - acc: 0.2094\n",
            "\n",
            "epoch 175/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9337 - acc: 0.2097\n",
            "Saving checkpoint for epoch 175 at ./checkpoints2/train\\ckpt-35\n",
            "\n",
            "epoch 176/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9303 - acc: 0.2099\n",
            "\n",
            "epoch 177/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9269 - acc: 0.2101\n",
            "\n",
            "epoch 178/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9235 - acc: 0.2104\n",
            "\n",
            "epoch 179/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9202 - acc: 0.2106\n",
            "\n",
            "epoch 180/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9168 - acc: 0.2109\n",
            "Saving checkpoint for epoch 180 at ./checkpoints2/train\\ckpt-36\n",
            "\n",
            "epoch 181/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9135 - acc: 0.2111\n",
            "\n",
            "epoch 182/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9102 - acc: 0.2113\n",
            "\n",
            "epoch 183/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9069 - acc: 0.2116\n",
            "\n",
            "epoch 184/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9037 - acc: 0.2118\n",
            "\n",
            "epoch 185/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9004 - acc: 0.2120\n",
            "Saving checkpoint for epoch 185 at ./checkpoints2/train\\ckpt-37\n",
            "\n",
            "epoch 186/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8972 - acc: 0.2123\n",
            "\n",
            "epoch 187/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8941 - acc: 0.2125\n",
            "\n",
            "epoch 188/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8909 - acc: 0.2127\n",
            "\n",
            "epoch 189/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8877 - acc: 0.2129\n",
            "\n",
            "epoch 190/200\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8846 - acc: 0.2132\n",
            "Saving checkpoint for epoch 190 at ./checkpoints2/train\\ckpt-38\n",
            "\n",
            "epoch 191/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.8815 - acc: 0.2134\n",
            "\n",
            "epoch 192/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8784 - acc: 0.2136\n",
            "\n",
            "epoch 193/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8753 - acc: 0.2138\n",
            "\n",
            "epoch 194/200\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8722 - acc: 0.2141\n",
            "\n",
            "epoch 195/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8692 - acc: 0.2143\n",
            "Saving checkpoint for epoch 195 at ./checkpoints2/train\\ckpt-39\n",
            "\n",
            "epoch 196/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.8662 - acc: 0.2145\n",
            "\n",
            "epoch 197/200\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8632 - acc: 0.2147\n",
            "\n",
            "epoch 198/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.8602 - acc: 0.2149\n",
            "\n",
            "epoch 199/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.8572 - acc: 0.2151\n",
            "\n",
            "epoch 200/200\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.8543 - acc: 0.2153\n",
            "Saving checkpoint for epoch 200 at ./checkpoints2/train\\ckpt-40\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 200\n",
        "batch_size = 64\n",
        "metrics_names = ['loss', 'acc']\n",
        "# train_loss.reset_states()\n",
        "# train_accuracy.reset_states()\n",
        "for epoch in range(150, EPOCHS):\n",
        "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
        "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
        "\n",
        "    # inp -> question, tar -> answer\n",
        "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
        "\n",
        "        pb_i.add(batch_size, values=values)\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa114565",
      "metadata": {
        "id": "fa114565",
        "outputId": "98853583-c4db-4e81-879c-abe770555176"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 201/300\n",
            "111552/111527 [==============================] - 140s 1ms/step - loss: 2.8513 - acc: 0.2156\n",
            "\n",
            "epoch 202/300\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.8484 - acc: 0.2158\n",
            "\n",
            "epoch 203/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8455 - acc: 0.2160\n",
            "\n",
            "epoch 204/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8426 - acc: 0.2162\n",
            "\n",
            "epoch 205/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8398 - acc: 0.2164\n",
            "Saving checkpoint for epoch 205 at ./checkpoints2/train\\ckpt-41\n",
            "\n",
            "epoch 206/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8369 - acc: 0.2166\n",
            "\n",
            "epoch 207/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8341 - acc: 0.2168\n",
            "\n",
            "epoch 208/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8312 - acc: 0.2170\n",
            "\n",
            "epoch 209/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8284 - acc: 0.2172\n",
            "\n",
            "epoch 210/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8256 - acc: 0.2174\n",
            "Saving checkpoint for epoch 210 at ./checkpoints2/train\\ckpt-42\n",
            "\n",
            "epoch 211/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8228 - acc: 0.2176\n",
            "\n",
            "epoch 212/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8201 - acc: 0.2178\n",
            "\n",
            "epoch 213/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8173 - acc: 0.2180\n",
            "\n",
            "epoch 214/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8146 - acc: 0.2182\n",
            "\n",
            "epoch 215/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8118 - acc: 0.2184\n",
            "Saving checkpoint for epoch 215 at ./checkpoints2/train\\ckpt-43\n",
            "\n",
            "epoch 216/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8091 - acc: 0.2186\n",
            "\n",
            "epoch 217/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8064 - acc: 0.2188\n",
            "\n",
            "epoch 218/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8037 - acc: 0.2190\n",
            "\n",
            "epoch 219/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8011 - acc: 0.2192\n",
            "\n",
            "epoch 220/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7984 - acc: 0.2194\n",
            "Saving checkpoint for epoch 220 at ./checkpoints2/train\\ckpt-44\n",
            "\n",
            "epoch 221/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7958 - acc: 0.2195\n",
            "\n",
            "epoch 222/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7931 - acc: 0.2197\n",
            "\n",
            "epoch 223/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7905 - acc: 0.2199\n",
            "\n",
            "epoch 224/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7879 - acc: 0.2201\n",
            "\n",
            "epoch 225/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7853 - acc: 0.2203\n",
            "Saving checkpoint for epoch 225 at ./checkpoints2/train\\ckpt-45\n",
            "\n",
            "epoch 226/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7827 - acc: 0.2205\n",
            "\n",
            "epoch 227/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7802 - acc: 0.2207\n",
            "\n",
            "epoch 228/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7776 - acc: 0.2208\n",
            "\n",
            "epoch 229/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7751 - acc: 0.2210\n",
            "\n",
            "epoch 230/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7726 - acc: 0.2212\n",
            "Saving checkpoint for epoch 230 at ./checkpoints2/train\\ckpt-46\n",
            "\n",
            "epoch 231/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7700 - acc: 0.2214\n",
            "\n",
            "epoch 232/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7675 - acc: 0.2216\n",
            "\n",
            "epoch 233/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7651 - acc: 0.2217\n",
            "\n",
            "epoch 234/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7626 - acc: 0.2219\n",
            "\n",
            "epoch 235/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7601 - acc: 0.2221\n",
            "Saving checkpoint for epoch 235 at ./checkpoints2/train\\ckpt-47\n",
            "\n",
            "epoch 236/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7577 - acc: 0.2223\n",
            "\n",
            "epoch 237/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7552 - acc: 0.2225\n",
            "\n",
            "epoch 238/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7528 - acc: 0.2226\n",
            "\n",
            "epoch 239/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7504 - acc: 0.2228\n",
            "\n",
            "epoch 240/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7481 - acc: 0.2230\n",
            "Saving checkpoint for epoch 240 at ./checkpoints2/train\\ckpt-48\n",
            "\n",
            "epoch 241/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7457 - acc: 0.2231\n",
            "\n",
            "epoch 242/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7433 - acc: 0.2233\n",
            "\n",
            "epoch 243/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7410 - acc: 0.2235\n",
            "\n",
            "epoch 244/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7386 - acc: 0.2237\n",
            "\n",
            "epoch 245/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7363 - acc: 0.2238\n",
            "Saving checkpoint for epoch 245 at ./checkpoints2/train\\ckpt-49\n",
            "\n",
            "epoch 246/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7339 - acc: 0.2240\n",
            "\n",
            "epoch 247/300\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.7316 - acc: 0.2242\n",
            "\n",
            "epoch 248/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7292 - acc: 0.2243\n",
            "\n",
            "epoch 249/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7269 - acc: 0.2245\n",
            "\n",
            "epoch 250/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7245 - acc: 0.2247\n",
            "Saving checkpoint for epoch 250 at ./checkpoints2/train\\ckpt-50\n",
            "\n",
            "epoch 251/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7222 - acc: 0.2248\n",
            "\n",
            "epoch 252/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7199 - acc: 0.2250\n",
            "\n",
            "epoch 253/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7175 - acc: 0.2252\n",
            "\n",
            "epoch 254/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7152 - acc: 0.2253\n",
            "\n",
            "epoch 255/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7129 - acc: 0.2255\n",
            "Saving checkpoint for epoch 255 at ./checkpoints2/train\\ckpt-51\n",
            "\n",
            "epoch 256/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7107 - acc: 0.2256\n",
            "\n",
            "epoch 257/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7084 - acc: 0.2258\n",
            "\n",
            "epoch 258/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7062 - acc: 0.2260\n",
            "\n",
            "epoch 259/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7039 - acc: 0.2261\n",
            "\n",
            "epoch 260/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7017 - acc: 0.2263\n",
            "Saving checkpoint for epoch 260 at ./checkpoints2/train\\ckpt-52\n",
            "\n",
            "epoch 261/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6994 - acc: 0.2264\n",
            "\n",
            "epoch 262/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6972 - acc: 0.2266\n",
            "\n",
            "epoch 263/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6950 - acc: 0.2267\n",
            "\n",
            "epoch 264/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6928 - acc: 0.2269\n",
            "\n",
            "epoch 265/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6906 - acc: 0.2271\n",
            "Saving checkpoint for epoch 265 at ./checkpoints2/train\\ckpt-53\n",
            "\n",
            "epoch 266/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6884 - acc: 0.2272\n",
            "\n",
            "epoch 267/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6862 - acc: 0.2274\n",
            "\n",
            "epoch 268/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6841 - acc: 0.2275\n",
            "\n",
            "epoch 269/300\n",
            "111552/111527 [==============================] - 144s 1ms/step - loss: 2.6819 - acc: 0.2277\n",
            "\n",
            "epoch 270/300\n",
            "111552/111527 [==============================] - 144s 1ms/step - loss: 2.6797 - acc: 0.2278\n",
            "Saving checkpoint for epoch 270 at ./checkpoints2/train\\ckpt-54\n",
            "\n",
            "epoch 271/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6776 - acc: 0.2280\n",
            "\n",
            "epoch 272/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6754 - acc: 0.2281\n",
            "\n",
            "epoch 273/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6733 - acc: 0.2283\n",
            "\n",
            "epoch 274/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6711 - acc: 0.2284\n",
            "\n",
            "epoch 275/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6690 - acc: 0.2286\n",
            "Saving checkpoint for epoch 275 at ./checkpoints2/train\\ckpt-55\n",
            "\n",
            "epoch 276/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6668 - acc: 0.2287\n",
            "\n",
            "epoch 277/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6647 - acc: 0.2289\n",
            "\n",
            "epoch 278/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6626 - acc: 0.2290\n",
            "\n",
            "epoch 279/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6605 - acc: 0.2292\n",
            "\n",
            "epoch 280/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6584 - acc: 0.2293\n",
            "Saving checkpoint for epoch 280 at ./checkpoints2/train\\ckpt-56\n",
            "\n",
            "epoch 281/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6563 - acc: 0.2295\n",
            "\n",
            "epoch 282/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6542 - acc: 0.2296\n",
            "\n",
            "epoch 283/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6521 - acc: 0.2298\n",
            "\n",
            "epoch 284/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6500 - acc: 0.2299\n",
            "\n",
            "epoch 285/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6480 - acc: 0.2301\n",
            "Saving checkpoint for epoch 285 at ./checkpoints2/train\\ckpt-57\n",
            "\n",
            "epoch 286/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6459 - acc: 0.2302\n",
            "\n",
            "epoch 287/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6439 - acc: 0.2304\n",
            "\n",
            "epoch 288/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6418 - acc: 0.2305\n",
            "\n",
            "epoch 289/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6398 - acc: 0.2306\n",
            "\n",
            "epoch 290/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6378 - acc: 0.2308\n",
            "Saving checkpoint for epoch 290 at ./checkpoints2/train\\ckpt-58\n",
            "\n",
            "epoch 291/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6357 - acc: 0.2309\n",
            "\n",
            "epoch 292/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6337 - acc: 0.2311\n",
            "\n",
            "epoch 293/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6317 - acc: 0.2312\n",
            "\n",
            "epoch 294/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6298 - acc: 0.2313\n",
            "\n",
            "epoch 295/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6278 - acc: 0.2315\n",
            "Saving checkpoint for epoch 295 at ./checkpoints2/train\\ckpt-59\n",
            "\n",
            "epoch 296/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6258 - acc: 0.2316\n",
            "\n",
            "epoch 297/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6239 - acc: 0.2318\n",
            "\n",
            "epoch 298/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6220 - acc: 0.2319\n",
            "\n",
            "epoch 299/300\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6201 - acc: 0.2320\n",
            "\n",
            "epoch 300/300\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6182 - acc: 0.2322\n",
            "Saving checkpoint for epoch 300 at ./checkpoints2/train\\ckpt-60\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 300\n",
        "batch_size = 64\n",
        "metrics_names = ['loss', 'acc']\n",
        "# train_loss.reset_states()\n",
        "# train_accuracy.reset_states()\n",
        "for epoch in range(200, EPOCHS):\n",
        "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
        "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
        "\n",
        "    # inp -> question, tar -> answer\n",
        "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
        "\n",
        "        pb_i.add(batch_size, values=values)\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88154466",
      "metadata": {
        "id": "88154466",
        "outputId": "7d649ee2-5770-40aa-bb75-ab15e3f4e28e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "epoch 301/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6134 - acc: 0.2325\n",
            "\n",
            "epoch 302/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6115 - acc: 0.2326\n",
            "\n",
            "epoch 303/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6096 - acc: 0.2328\n",
            "\n",
            "epoch 304/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6078 - acc: 0.2329\n",
            "\n",
            "epoch 305/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6059 - acc: 0.2330\n",
            "Saving checkpoint for epoch 305 at ./checkpoints2/train\\ckpt-61\n",
            "\n",
            "epoch 306/350\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.6041 - acc: 0.2331\n",
            "\n",
            "epoch 307/350\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.6023 - acc: 0.2333\n",
            "\n",
            "epoch 308/350\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.6005 - acc: 0.2334\n",
            "\n",
            "epoch 309/350\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.5986 - acc: 0.2335\n",
            "\n",
            "epoch 310/350\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.5968 - acc: 0.2337\n",
            "Saving checkpoint for epoch 310 at ./checkpoints2/train\\ckpt-62\n",
            "\n",
            "epoch 311/350\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.5950 - acc: 0.2338\n",
            "\n",
            "epoch 312/350\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.5932 - acc: 0.2339\n",
            "\n",
            "epoch 313/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5914 - acc: 0.2340\n",
            "\n",
            "epoch 314/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5896 - acc: 0.2342\n",
            "\n",
            "epoch 315/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5878 - acc: 0.2343\n",
            "Saving checkpoint for epoch 315 at ./checkpoints2/train\\ckpt-63\n",
            "\n",
            "epoch 316/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5861 - acc: 0.2344\n",
            "\n",
            "epoch 317/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5843 - acc: 0.2345\n",
            "\n",
            "epoch 318/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5825 - acc: 0.2346\n",
            "\n",
            "epoch 319/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5808 - acc: 0.2348\n",
            "\n",
            "epoch 320/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5790 - acc: 0.2349\n",
            "Saving checkpoint for epoch 320 at ./checkpoints2/train\\ckpt-64\n",
            "\n",
            "epoch 321/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5773 - acc: 0.2350\n",
            "\n",
            "epoch 322/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5755 - acc: 0.2351\n",
            "\n",
            "epoch 323/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5738 - acc: 0.2352\n",
            "\n",
            "epoch 324/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5721 - acc: 0.2354\n",
            "\n",
            "epoch 325/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5704 - acc: 0.2355\n",
            "Saving checkpoint for epoch 325 at ./checkpoints2/train\\ckpt-65\n",
            "\n",
            "epoch 326/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5686 - acc: 0.2356\n",
            "\n",
            "epoch 327/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5670 - acc: 0.2357\n",
            "\n",
            "epoch 328/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5653 - acc: 0.2358\n",
            "\n",
            "epoch 329/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5636 - acc: 0.2360\n",
            "\n",
            "epoch 330/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5619 - acc: 0.2361\n",
            "Saving checkpoint for epoch 330 at ./checkpoints2/train\\ckpt-66\n",
            "\n",
            "epoch 331/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5602 - acc: 0.2362\n",
            "\n",
            "epoch 332/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5586 - acc: 0.2363\n",
            "\n",
            "epoch 333/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5569 - acc: 0.2364\n",
            "\n",
            "epoch 334/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5553 - acc: 0.2365\n",
            "\n",
            "epoch 335/350\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.5536 - acc: 0.2367\n",
            "Saving checkpoint for epoch 335 at ./checkpoints2/train\\ckpt-67\n",
            "\n",
            "epoch 336/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5520 - acc: 0.2368\n",
            "\n",
            "epoch 337/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5504 - acc: 0.2369\n",
            "\n",
            "epoch 338/350\n",
            "111552/111527 [==============================] - 141s 1ms/step - loss: 2.5488 - acc: 0.2370\n",
            "\n",
            "epoch 339/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5472 - acc: 0.2371\n",
            "\n",
            "epoch 340/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5456 - acc: 0.2372\n",
            "Saving checkpoint for epoch 340 at ./checkpoints2/train\\ckpt-68\n",
            "\n",
            "epoch 341/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5440 - acc: 0.2374\n",
            "\n",
            "epoch 342/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5424 - acc: 0.2375\n",
            "\n",
            "epoch 343/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5408 - acc: 0.2376\n",
            "\n",
            "epoch 344/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5393 - acc: 0.2377\n",
            "\n",
            "epoch 345/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5377 - acc: 0.2378\n",
            "Saving checkpoint for epoch 345 at ./checkpoints2/train\\ckpt-69\n",
            "\n",
            "epoch 346/350\n",
            "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5362 - acc: 0.2379\n",
            "\n",
            "epoch 347/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5347 - acc: 0.2380\n",
            "\n",
            "epoch 348/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5332 - acc: 0.2381\n",
            "\n",
            "epoch 349/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5316 - acc: 0.2383\n",
            "\n",
            "epoch 350/350\n",
            "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5301 - acc: 0.2384\n",
            "Saving checkpoint for epoch 350 at ./checkpoints2/train\\ckpt-70\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 350\n",
        "batch_size = 64\n",
        "metrics_names = ['loss', 'acc']\n",
        "# train_loss.reset_states()\n",
        "# train_accuracy.reset_states()\n",
        "for epoch in range(300, EPOCHS):\n",
        "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
        "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
        "\n",
        "    # inp -> question, tar -> answer\n",
        "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
        "\n",
        "        pb_i.add(batch_size, values=values)\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58fe7b10",
      "metadata": {
        "id": "58fe7b10"
      },
      "source": [
        "# EPOCH:350, I think its enough, let's check what type of REPLIES that CHATBOT is generating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "578270c4",
      "metadata": {
        "id": "578270c4"
      },
      "outputs": [],
      "source": [
        "# joblib.dump(tokenizer_q, \"tokenizer_q\")\n",
        "# joblib.dump(tokenizer_a, \"tokenizer_a\")\n",
        "# transformer.save_weights('transformer_model/weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c93b48c",
      "metadata": {
        "id": "5c93b48c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "    sentence = sentence.split(\" \")\n",
        "    predicted_sentence = predicted_sentence.split(\" \")\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "\n",
        "\n",
        "def plot_attention_weights(attention,tokenizer_q, tokenizer_a, sentence, result, layer):\n",
        "\n",
        "    fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "    sentence = tokenizer_q.encode(sentence)\n",
        "\n",
        "    attention = tf.squeeze(attention[layer], axis=0)\n",
        "    #(1, 8, 5, 4) --> (8, 5, 4)\n",
        "    for head in range(attention.shape[0]):\n",
        "        ax = fig.add_subplot(2, 4, head+1)\n",
        "\n",
        "        # plot the attention weights [:-1, :]\n",
        "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
        "        fontdict = {'fontsize': 10}\n",
        "\n",
        "        ax.set_xticks(range(len(sentence)+2))\n",
        "        ax.set_yticks(range(len(result)-1))\n",
        "\n",
        "        ax.set_ylim(len(result)-1.5, -0.5)\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        x = ['<start>']+[tokenizer_q.decode([i]) for i in sentence]+['<end>']\n",
        "        y = [tokenizer_a.decode([i]) for i in result if i < tokenizer_a.vocab_size]\n",
        "        ax.set_xticklabels([''] + x, fontdict=fontdict, rotation=90)\n",
        "        ax.set_yticklabels([''] + y, fontdict=fontdict)\n",
        "\n",
        "\n",
        "        ax.set_xlabel('Head {}'.format(head+1))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "MAX_LENGTH = 27\n",
        "\n",
        "def evaluate(inp_sentence, model,  tokenizer_q, tokenizer_a):\n",
        "    start_token = [tokenizer_q.vocab_size]\n",
        "    end_token = [tokenizer_q.vocab_size + 1]\n",
        "\n",
        "    # All questions has the start and end token\n",
        "    inp_sentence = start_token + tokenizer_q.encode(inp_sentence) + end_token\n",
        "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "\n",
        "    # 'answers' start token : 27358\n",
        "    decoder_input = [tokenizer_a.vocab_size]\n",
        "    decoder_input = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "    for i in range(MAX_LENGTH):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, decoder_input)\n",
        "\n",
        "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "        predictions, attention_weights = model(encoder_input,\n",
        "                                                     decoder_input,\n",
        "                                                     False,\n",
        "                                                     enc_padding_mask,\n",
        "                                                     combined_mask,\n",
        "                                                     dec_padding_mask)\n",
        "\n",
        "        # select the last word from the seq_len dimension\n",
        "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        # return the result if the predicted_id is equal to the end token\n",
        "        if predicted_id == tokenizer_a.vocab_size+1:\n",
        "            print(f\"=============\\nGot end token\\n=============\")\n",
        "            return tf.squeeze(decoder_input, axis=0), attention_weights\n",
        "\n",
        "        # concatentate the predicted_id to the output which is given to the decoder\n",
        "        # as its input.\n",
        "        decoder_input = tf.concat([decoder_input, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(decoder_input, axis=0), attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f3aad84",
      "metadata": {
        "id": "4f3aad84"
      },
      "outputs": [],
      "source": [
        "def reply(sentence, transformer,  tokenizer_q, tokenizer_a, plot=''):\n",
        "    result, attention_weights = evaluate(sentence, transformer,  tokenizer_q, tokenizer_a)\n",
        "#     print(\"Attention_Blocks:\", list(attention_weights.keys()))\n",
        "    predicted_sentence = tokenizer_a.decode([i for i in result\n",
        "                                            if i < tokenizer_a.vocab_size])\n",
        "\n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Predicted translation: {}'.format(predicted_sentence))\n",
        "    if plot:\n",
        "        plot_attention_weights(attention_weights,tokenizer_q, tokenizer_a, sentence, result, plot)\n",
        "    return sentence, predicted_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b5f1253",
      "metadata": {
        "id": "1b5f1253",
        "outputId": "a045cbd3-c972-4053-ba50-039247790d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Attention_Blocks: ['decoder_layer1_block1', 'decoder_layer1_block2', 'decoder_layer2_block1', 'decoder_layer2_block2']\n",
            "Input: i was told ten thousand in each pack\n",
            "Predicted translation: you did not count it\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 8 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "inp_sentence = \"i was told ten thousand in each pack\"\n",
        "reply(inp_sentence, transformer,  tokenizer_q, tokenizer_a, \"decoder_layer2_block2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3db5f71",
      "metadata": {
        "id": "b3db5f71"
      },
      "source": [
        "## OUTPUTS are not absurd at all, It has LEARNED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "298cfd21",
      "metadata": {
        "id": "298cfd21",
        "outputId": "360ee881-6a05-42b2-d8aa-8aa04cee402f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Attention_Blocks: ['decoder_layer1_block1', 'decoder_layer1_block2', 'decoder_layer2_block1', 'decoder_layer2_block2']\n",
            "Input: i did not sleep well\n",
            "Predicted translation: great bye\n"
          ]
        }
      ],
      "source": [
        "inp_sentence = \"i did not sleep well\"\n",
        "reply(inp_sentence, transformer,  tokenizer_q, tokenizer_a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afd920ba",
      "metadata": {
        "scrolled": true,
        "id": "afd920ba",
        "outputId": "ef9e53c3-f392-4f11-8d30-64067229a6aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>84608</th>\n",
              "      <td>irwin professional journalism time now go back...</td>\n",
              "      <td>i will frank i will something came up okay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6889</th>\n",
              "      <td>you mean with you and that woman chained to ya...</td>\n",
              "      <td>you treat folks special when they company it i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125210</th>\n",
              "      <td>why has he bothered you before</td>\n",
              "      <td>is it news to you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24800</th>\n",
              "      <td>i was told ten thousand in each pack</td>\n",
              "      <td>you did not count it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76507</th>\n",
              "      <td>he just wants me to make him cinnamon cookies ...</td>\n",
              "      <td>i think he wants more than your cookies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81602</th>\n",
              "      <td>no no  you boys are tired</td>\n",
              "      <td>no we are not  jack</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 question  \\\n",
              "84608   irwin professional journalism time now go back...   \n",
              "6889    you mean with you and that woman chained to ya...   \n",
              "125210                     why has he bothered you before   \n",
              "24800                i was told ten thousand in each pack   \n",
              "76507   he just wants me to make him cinnamon cookies ...   \n",
              "81602                           no no  you boys are tired   \n",
              "\n",
              "                                                   answer  \n",
              "84608          i will frank i will something came up okay  \n",
              "6889    you treat folks special when they company it i...  \n",
              "125210                                  is it news to you  \n",
              "24800                                you did not count it  \n",
              "76507             i think he wants more than your cookies  \n",
              "81602                                 no we are not  jack  "
            ]
          },
          "execution_count": 1075,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.iloc[400:406]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14569967",
      "metadata": {
        "id": "14569967",
        "outputId": "b2c9f495-6bb4-4187-bd90-0af88333345f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23940</th>\n",
              "      <td>south america</td>\n",
              "      <td>we leave miami in an hour soon is we get some ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54489</th>\n",
              "      <td>i did not sleep well</td>\n",
              "      <td>do you want to talk about it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15996</th>\n",
              "      <td>really both of you why not</td>\n",
              "      <td>just because</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38692</th>\n",
              "      <td>what department store did they go to</td>\n",
              "      <td>mcintire is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21519</th>\n",
              "      <td>i should not say this but you are pretty gabri...</td>\n",
              "      <td>really i always think myself so ugly no not ug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116659</th>\n",
              "      <td>i do not know</td>\n",
              "      <td>do not know what</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 question  \\\n",
              "23940                                       south america   \n",
              "54489                                i did not sleep well   \n",
              "15996                          really both of you why not   \n",
              "38692                what department store did they go to   \n",
              "21519   i should not say this but you are pretty gabri...   \n",
              "116659                                      i do not know   \n",
              "\n",
              "                                                   answer  \n",
              "23940   we leave miami in an hour soon is we get some ...  \n",
              "54489                        do you want to talk about it  \n",
              "15996                                        just because  \n",
              "38692                                         mcintire is  \n",
              "21519   really i always think myself so ugly no not ug...  \n",
              "116659                                   do not know what  "
            ]
          },
          "execution_count": 1070,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation.iloc[400:406]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a112d4ac",
      "metadata": {
        "scrolled": true,
        "id": "a112d4ac",
        "outputId": "33cd693b-993f-4dcf-b839-be0ac5a53f10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: and the fifty is all gone huh who is the ten for\n",
            "Predicted translation: the chance is impossible\n",
            "Actual: the websters\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: rocky do you have any representation a manager\n",
            "Predicted translation: no  just me\n",
            "Actual: no  just me\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: jeanne let me introduce the king is half brother the dogged lord dunois\n",
            "Predicted translation: then lord have given my lord is name in rome\n",
            "Actual: then lord dunois show me the way to the other side of the river\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: father martineau but i do not see him as a candidate\n",
            "Predicted translation: could there have been anyone else\n",
            "Actual: could there have been anyone else\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: i have not read you your rights\n",
            "Predicted translation: would you mind saying that into your bag\n",
            "Actual: would you mind saying that into your bag\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: is this a good spot\n",
            "Predicted translation: i am not sure look at it  time is it  time to look at it\n",
            "Actual: i am not burying him here\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: my turn what is your favorite song\n",
            "Predicted translation: same time when you were at school\n",
            "Actual: soft and wet by the artist formerly known as prince\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: why do not you dump it mail it off give the fucking fbi a present\n",
            "Predicted translation: why do not you dump the fat lady\n",
            "Actual: why do not you dump the fat lady\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: time to impact\n",
            "Predicted translation: twelve seconds\n",
            "Actual: twelve seconds\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: run for your lives boys  it is that great twogun dogcatcher from kansas\n",
            "Predicted translation: you you seen all the in a to years old man\n",
            "Actual: mcmasters is not it  listen you seen a black stallion with\n"
          ]
        }
      ],
      "source": [
        "import nltk.translate.bleu_score as bleu\n",
        "from tqdm import tqdm\n",
        "test_q = train[\"question\"].values[:10]\n",
        "test_a = train[\"answer\"].values[:10]\n",
        "bss = []\n",
        "for i in range(10):\n",
        "    input_test_sentence = test_q[i]\n",
        "    input_sentence, pred_string = reply(input_test_sentence, transformer,  tokenizer_q, tokenizer_a, plot='')\n",
        "    print(\"Actual:\", test_a[i])\n",
        "    reference = [test_a[i].split()] # the original\n",
        "    translation = pred_string.split() # trasilated using model\n",
        "#     bs = bleu.sentence_bleu(reference, translation)\n",
        "#     bss.append(bs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c86d5e23",
      "metadata": {
        "id": "c86d5e23",
        "outputId": "709738ed-5183-4b72-f595-77fce423e66f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: you have been talking to her on the phone for weeks\n",
            "Predicted translation: yes i can imagine that she was there that i am\n",
            "Actual: it was only a few times\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: into our group\n",
            "Predicted translation: leave me at the house\n",
            "Actual: it is really hard to do some kids try for all ofhigh school and never make it\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: we will do that but how are we going to hold him he can change himself into a man he can disappear\n",
            "Predicted translation: where should we be  we still have to move a rock n roll\n",
            "Actual: that is the chance we have to take\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: oh nothing wade how ya doin there\n",
            "Predicted translation: holy cow\n",
            "Actual: stan grossman looked at your proposal says it is pretty sweet\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: i do not understand \n",
            "Predicted translation: i am so scared i did not take you back\n",
            "Actual: did you say rape her\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: you are missing the game for us\n",
            "Predicted translation: you are the one that can not be done\n",
            "Actual: no  i am missing the game for you\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: i took sleeping pills\n",
            "Predicted translation: i should have taken that great life to see your father and him has gone to hell out of there\n",
            "Actual: do you know where you are fran\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: this is all cause of your mom kyle she is such a bitch  agh i mean  she is such a meanie\n",
            "Predicted translation: i know her there would be more to her again  i never met her i am not sure\n",
            "Actual: and she is getting worse\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: the insurance business\n",
            "Predicted translation: jesus christ an old man got that woman in my life\n",
            "Actual: it is a good honest business is not it\n",
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: have you evacuated anyone\n",
            "Predicted translation: or what about us\n",
            "Actual: only that floor\n"
          ]
        }
      ],
      "source": [
        "import nltk.translate.bleu_score as bleu\n",
        "from tqdm import tqdm\n",
        "test_q = validation[\"question\"].values[100:110]\n",
        "test_a = validation[\"answer\"].values[100:110]\n",
        "bss = []\n",
        "for i in range(10):\n",
        "    input_test_sentence = test_q[i]\n",
        "    input_sentence, pred_string = reply(input_test_sentence, load_transformer,  tokenizer_q, tokenizer_a, plot='')\n",
        "    print(\"Actual:\", test_a[i])\n",
        "    reference = [test_a[i].split()] # the original\n",
        "    translation = pred_string.split() # trasilated using model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5221356",
      "metadata": {
        "id": "f5221356",
        "outputId": "de3bf62b-49d6-4999-9ec4-9f1702dd6908"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x27e0fd93940>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# num_layers = 2\n",
        "# d_model = 256\n",
        "# dff = 512\n",
        "# num_heads = 8\n",
        "# input_vocab_size = tokenizer_q.vocab_size + 2\n",
        "# target_vocab_size = tokenizer_a.vocab_size + 2\n",
        "# dropout_rate = 0.1\n",
        "\n",
        "# load_transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "#                           input_vocab_size, target_vocab_size,\n",
        "#                           pe_input=input_vocab_size,\n",
        "#                           pe_target=target_vocab_size,\n",
        "#                           rate=dropout_rate)\n",
        "# load_transformer.load_weights('transformer_model/weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d2d6845",
      "metadata": {
        "id": "5d2d6845",
        "outputId": "e55247de-0b12-4bad-afb0-82ae24e11b25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: i was told ten thousand in each pack\n",
            "Predicted translation: you did not count it\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 8 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "('i was told ten thousand in each pack', 'you did not count it')"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp_sentence = \"i was told ten thousand in each pack\"\n",
        "reply(inp_sentence, load_transformer,  tokenizer_q, tokenizer_a, \"decoder_layer2_block2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76541209",
      "metadata": {
        "id": "76541209"
      },
      "source": [
        "* Results are great, better than encoder-decoder with bahadenau attention mechanism\n",
        "* Still we can see the results are not perfect, because the architecture has less parameters plus the dataset is not very big and transformers works close to humans with large data and large trainable parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "144f2d50",
      "metadata": {
        "id": "144f2d50"
      },
      "source": [
        "# On random inputs!\n",
        "### Results are genuine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c357afa8",
      "metadata": {
        "id": "c357afa8",
        "outputId": "1a6f98b5-84ed-46e6-ac1b-e328733acff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: hi\n",
            "Predicted translation: hi\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('hi', 'hi')"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp_sentence = \"hi\"\n",
        "reply(inp_sentence, load_transformer,  tokenizer_q, tokenizer_a)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8dbf4e6",
      "metadata": {
        "id": "a8dbf4e6",
        "outputId": "254f18a1-9156-465c-f696-6991528bffd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: Where have you been\n",
            "Predicted translation: i think you came up with this town again\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('Where have you been', 'i think you came up with this town again')"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp_sentence = \"Where have you been\"\n",
        "reply(inp_sentence, load_transformer,  tokenizer_q, tokenizer_a)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b357781a",
      "metadata": {
        "id": "b357781a"
      },
      "source": [
        "#### Making sense haha : ) \"who are you\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1d86b1c",
      "metadata": {
        "id": "b1d86b1c",
        "outputId": "7d199675-d295-4f9a-a6f2-64d7ff6f2def"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: who are you\n",
            "Predicted translation: i am the guy who is he\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('who are you', 'i am the guy who is he')"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp_sentence = \"who are you\"\n",
        "reply(inp_sentence, load_transformer,  tokenizer_q, tokenizer_a)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58f0fab3",
      "metadata": {
        "id": "58f0fab3"
      },
      "source": [
        "####  Again making sense \"where do you live\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "635f4b9c",
      "metadata": {
        "id": "635f4b9c",
        "outputId": "c5cf3263-13ab-45fb-bec3-4fdbf5e58c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: where do you live\n",
            "Predicted translation: in new york\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('where do you live', 'in new york')"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp_sentence = \"where do you live\"\n",
        "reply(inp_sentence, load_transformer,  tokenizer_q, tokenizer_a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ecdc49",
      "metadata": {
        "id": "88ecdc49",
        "outputId": "16b8ab8a-648e-4257-f19b-ab6dfb9ff137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: what is your name\n",
            "Predicted translation: my name is sir te i am not the one i am talking about you\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('what is your name',\n",
              " 'my name is sir te i am not the one i am talking about you')"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp_sentence = \"what is your name\"\n",
        "reply(inp_sentence, load_transformer,  tokenizer_q, tokenizer_a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5f480ff",
      "metadata": {
        "scrolled": true,
        "id": "b5f480ff",
        "outputId": "72b23484-ae9f-431b-95b9-32bd1dbcd629"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============\n",
            "Got end token\n",
            "=============\n",
            "Input: why are you angry with me is there anything i did wrong\n",
            "Predicted translation: i did not know you had something to do for me\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('why are you angry with me is there anything i did wrong',\n",
              " 'i did not know you had something to do for me')"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp_sentence = \"why are you angry with me is there anything i did wrong\"\n",
        "reply(inp_sentence, load_transformer,  tokenizer_q, tokenizer_a)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e57d9937",
      "metadata": {
        "id": "e57d9937"
      },
      "source": [
        "# Even with this small architecture its working fine, what else it could do If I train it with trainable parameters with more data"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}