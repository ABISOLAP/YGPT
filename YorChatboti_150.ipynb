{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eRu8s0Uv7ILG",
        "outputId": "a00c79ab-ec27-4a5a-a411-39774489bb72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       Question  \\\n",
              "0            Ẹ ǹlẹ́ o, Ẹlẹ́ran.   \n",
              "1               Ṣé ajé ń wọgbá?   \n",
              "2           Eélòó ni kilo ẹran?   \n",
              "3         Ṣé jálẹ̀jálẹ̀ nì yẹn?   \n",
              "4  Ṣe bí o ti mọ, ẹlẹ́wà Ṣàpọn.   \n",
              "\n",
              "                                              Answer  \n",
              "0                                Ẹ ǹlẹ́ o, Oníbàárà.  \n",
              "1                                        Olúwa ṣeun.  \n",
              "2                                   N1, 300 ni kílò.  \n",
              "3  Bẹ́ẹ̀ni, jálẹ̀jálẹ̀ nì yẹn. Kódà, àwọn kan ń t...  \n",
              "4                                        Òótó lẹ sọ.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48ef3152-f06f-45f8-a32f-e427529339eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ẹ ǹlẹ́ o, Ẹlẹ́ran.</td>\n",
              "      <td>Ẹ ǹlẹ́ o, Oníbàárà.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ṣé ajé ń wọgbá?</td>\n",
              "      <td>Olúwa ṣeun.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Eélòó ni kilo ẹran?</td>\n",
              "      <td>N1, 300 ni kílò.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ṣé jálẹ̀jálẹ̀ nì yẹn?</td>\n",
              "      <td>Bẹ́ẹ̀ni, jálẹ̀jálẹ̀ nì yẹn. Kódà, àwọn kan ń t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ṣe bí o ti mọ, ẹlẹ́wà Ṣàpọn.</td>\n",
              "      <td>Òótó lẹ sọ.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48ef3152-f06f-45f8-a32f-e427529339eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-48ef3152-f06f-45f8-a32f-e427529339eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-48ef3152-f06f-45f8-a32f-e427529339eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-add270ee-edde-473d-8b1e-5137d90a4c55\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-add270ee-edde-473d-8b1e-5137d90a4c55')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-add270ee-edde-473d-8b1e-5137d90a4c55 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1229,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 748,\n        \"samples\": [\n          \" Gbow\\u00f3 re\\u0323\",\n          \"\\u1eb8 k\\u00fa is\\u1eb9\\u0301 o. B\\u00e1wo ni?\",\n          \"\\u00d3 d\\u00e1a. \\u00c0b\\u00f9s\\u00ed Ol\\u00fawa o. \\u1eb8 gba ow\\u00f3.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 693,\n        \"samples\": [\n          \" M\\u00e0\\u00e1 t\\u00e0 \\u00e1 f\\u00fan un y\\u00edn n\\u00ed  \\u1ecdg\\u1ecd\\u0301\\u1ecd\\u0300ru\\u0300n-\\u00fan m\\u00e9j\\u00ec l\\u00e9l\\u00e0\\u00e1d\\u1ecd\\u0301rin \\u1eb9gb\\u1eb9\\u0300run\",\n          \"\\u1eccg\\u1ecd\\u0301r\\u00f9n-\\u00fan m\\u00e9j\\u00ec \\u00e0ti \\u00e0\\u00e1d\\u1ecd\\u0301ta n\\u00e1\\u00edr\\u00e0\",\n          \"\\u1eb8 \\u1e63\\u00e9 o. \\u1eb8 gba \\u1e63\\u1eb9\\u0301\\u0144j\\u00ec y\\u00edn\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = 'https://docs.google.com/spreadsheets/d/1R7kmn9LtcGZFUCplZVN804NXsGWyUBHF/export?format=xlsx'\n",
        "sheet_name = 'combinedata'\n",
        "\n",
        "# Read the specific sheet into a DataFrame\n",
        "df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
        "\n",
        "# Display the DataFrame\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OznBfrZAAzPv",
        "outputId": "5a0a2117-57e4-455a-e557-1d355155048a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1229 entries, 0 to 1228\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Question  1229 non-null   object\n",
            " 1   Answer    1229 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 19.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.dropna()"
      ],
      "metadata": {
        "id": "QfiAR-caBAs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzhtfe2SBEvZ",
        "outputId": "3cfab568-24b3-4b57-91fc-cc997f6adf28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1229 entries, 0 to 1228\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Question  1229 non-null   object\n",
            " 1   Answer    1229 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 19.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data and separate into train, validation and test data\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from pathlib import Path\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "BJzYmiox7Vln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "ZW_-oqaN7WL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now split up the data into train and validation sets\n",
        "data=df.copy()\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "raw_train_dataset = data[:n]\n",
        "raw_validation_dataset = data[n:]"
      ],
      "metadata": {
        "id": "BFAqxlOn75-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create tokenizers\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace"
      ],
      "metadata": {
        "id": "MI9j9Amz8vkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(\"./tokenizer_que\")\n",
        "os.mkdir(\"./tokenizer_ans\")"
      ],
      "metadata": {
        "id": "h_AUyNyD8x02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ds_iterator(raw_train_dataset, lang):\n",
        "    for _, row in raw_train_dataset.iterrows():\n",
        "        yield row[lang]\n",
        "\n"
      ],
      "metadata": {
        "id": "KDT-iAVt_xgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Source Tokenizer - Question\n",
        "tokenizer_en = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "trainer_en = BpeTrainer(min_frequency=2, special_tokens=[\"[PAD]\",\"[UNK]\",\"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "# We’ll also need to add a pre-tokenizer to split our input into words as without a pre-tokenizer, we might get tokens that overlap several words: for instance we could get a \"there is\" token since those two words often appear next to each other.\n",
        "# Using a pre-tokenizer will ensure no token is bigger than a word returned by the pre-tokenizer.\n",
        "tokenizer_en.pre_tokenizer = Whitespace()\n",
        "tokenizer_en.train_from_iterator(get_ds_iterator(raw_train_dataset, \"Question\"), trainer=trainer_en)\n",
        "tokenizer_en.save(\"./tokenizer_que/tokenizer_question.json\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LSLR8XMp9lat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Target Tokenizer - answer\n",
        "tokenizer_my = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "trainer_my = BpeTrainer(min_frequency=2, special_tokens=[\"[PAD]\",\"[UNK]\",\"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "tokenizer_my.pre_tokenizer = Whitespace()\n",
        "tokenizer_my.train_from_iterator(get_ds_iterator(raw_train_dataset, \"Answer\"), trainer=trainer_my)\n",
        "tokenizer_my.save(\"./tokenizer_ans/tokenizer_answer.json\")\n"
      ],
      "metadata": {
        "id": "F3prYw38-_IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_dataset[0:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "hineO27e_TZb",
        "outputId": "6e05a35e-8617-44fb-b027-8088e3c53c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Question               Answer\n",
              "0  Ẹ ǹlẹ́ o, Ẹlẹ́ran.  Ẹ ǹlẹ́ o, Oníbàárà."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e78b91d-ddc2-41f0-9601-6890e3741bf2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ẹ ǹlẹ́ o, Ẹlẹ́ran.</td>\n",
              "      <td>Ẹ ǹlẹ́ o, Oníbàárà.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e78b91d-ddc2-41f0-9601-6890e3741bf2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e78b91d-ddc2-41f0-9601-6890e3741bf2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e78b91d-ddc2-41f0-9601-6890e3741bf2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"raw_train_dataset[0:1]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u1eb8 \\u01f9l\\u1eb9\\u0301 o, \\u1eb8l\\u1eb9\\u0301ran.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u1eb8 \\u01f9l\\u1eb9\\u0301 o, On\\u00edb\\u00e0\\u00e1r\\u00e0.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_que = Tokenizer.from_file(\"./tokenizer_que/tokenizer_question.json\")\n",
        "tokenizer_ans = Tokenizer.from_file(\"./tokenizer_ans/tokenizer_answer.json\")\n",
        "\n",
        "source_vocab_size = tokenizer_que.get_vocab_size()\n",
        "target_vocab_size = tokenizer_ans.get_vocab_size()\n",
        "\n",
        "# to calculate the max sequence lenth in the entire training dataset for the source and target dataset\n",
        "max_seq_len_source = 0\n",
        "max_seq_len_target = 0\n",
        "\n",
        "for  _, data in raw_train_dataset.iterrows():\n",
        "    enc_ids = tokenizer_en.encode(data['Question']).ids\n",
        "    dec_ids = tokenizer_my.encode(data['Answer']).ids\n",
        "    max_seq_len_source = max(max_seq_len_source, len(enc_ids))\n",
        "    max_seq_len_target = max(max_seq_len_target, len(dec_ids))\n",
        "\n",
        "print(f'max_seqlen_source: {max_seq_len_source}')   #99 - can be different in your case\n",
        "print(f'max_seqlen_target: {max_seq_len_target}')   #109 - can be different in your case\n",
        "\n",
        "# to make it standard for our training we'll just take max_seq_len_source and add 20-50 to cover the additional tokens such as PAD, CLS, SEP\n",
        "max_seq_len = 225"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bk6PUxe_RMz",
        "outputId": "337a8d71-974d-4c8e-f479-ff7072e3d4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_seqlen_source: 81\n",
            "max_seqlen_target: 175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sx-cYv35WbM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ahxo3i4wXHe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "reqfC1YNB_Wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Transform raw dataset to the encoded dataset that can be processed by the model\n",
        "class EncodeDataset(Dataset):\n",
        "    def __init__(self, raw_dataset, max_seq_len):\n",
        "        super().__init__()\n",
        "        self.raw_dataset = raw_dataset\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.raw_dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # fetching the single data for the given index value that consist of both question and response.\n",
        "        raw_text = self.raw_dataset.iloc[index]\n",
        "\n",
        "        # separating text by question and answer which will be later used for encoding.\n",
        "        source_text = raw_text[\"Question\"]\n",
        "        target_text = raw_text['Answer']\n",
        "\n",
        "        # Encoding both question and answer text\n",
        "        source_text_encoded = tokenizer_en.encode(source_text).ids\n",
        "        target_text_encoded = tokenizer_my.encode(target_text).ids\n",
        "\n",
        "        # Convert the CLS, SEP and PAD tokens to their corresponding index id in vocabulary using tokenizer [the id would be same with either tokenizers]\n",
        "        CLS_ID = torch.tensor([tokenizer_my.token_to_id(\"[CLS]\")], dtype=torch.int64)\n",
        "        SEP_ID = torch.tensor([tokenizer_my.token_to_id(\"[SEP]\")], dtype=torch.int64)\n",
        "        PAD_ID = torch.tensor([tokenizer_my.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
        "\n",
        "        # To train the model, the sequence lenth of each input should be equal max seq length. Hence additional number of padding will be added to the input sequence if the length is not equal to the max seq length.\n",
        "        num_source_padding = self.max_seq_len - len(source_text_encoded) - 2\n",
        "        num_target_padding = self.max_seq_len - len(target_text_encoded) - 1\n",
        "\n",
        "        encoder_padding = torch.tensor([PAD_ID] * num_source_padding, dtype = torch.int64)\n",
        "        decoder_padding = torch.tensor([PAD_ID] * num_target_padding, dtype = torch.int64)\n",
        "\n",
        "        # encoder_input has the first token as start of senstence - CLS_ID, followed by source encoding which is then followed by the end of sentence token - SEP.\n",
        "        # To reach the required max_seq_len, addition PAD token will be added at the end.\n",
        "        encoder_input = torch.cat([CLS_ID, torch.tensor(source_text_encoded, dtype=torch.int64), SEP_ID, encoder_padding], dim=0)\n",
        "\n",
        "        # decoder_input has the first token as start of senstence - CLS_ID, followed by target encoding.\n",
        "        # To reach the required max_seq_len, addition PAD token will be added at the end. There is no end of sentence token - SEP in decoder input.\n",
        "        decoder_input = torch.cat([CLS_ID, torch.tensor(target_text_encoded, dtype=torch.int64), decoder_padding ], dim=0)\n",
        "\n",
        "        # target_label is required for the loss calculation during training to compare between the predicted and target label.\n",
        "        # target_label has the first token as target encoding followed by actual target encoding. There is no start of sentence token - CLS in target label.\n",
        "        # To reach the required max_seq_len, addition PAD token will be added at the end.\n",
        "        target_label = torch.cat([torch.tensor(target_text_encoded, dtype=torch.int64),SEP_ID,decoder_padding], dim=0)\n",
        "\n",
        "        # Since we've added extra padding token with input encoding, we don't want this token to be trained by model.\n",
        "        # So, we'll use encoder mask to nullify the padding value prior to producing output of self attention in encoder block\n",
        "        encoder_mask = (encoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int()\n",
        "\n",
        "        # We don't want any token to get influence the future token during the decoding stage. Hence, Causal mask is being implemented during masked multihead attention to handle this.\n",
        "        decoder_mask = (decoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int() & causal_mask(decoder_input.size(0))\n",
        "\n",
        "        return {\n",
        "            'encoder_input': encoder_input,\n",
        "            'decoder_input': decoder_input,\n",
        "            'target_label': target_label,\n",
        "            'encoder_mask': encoder_mask,\n",
        "            'decoder_mask': decoder_mask,\n",
        "            'source_text': source_text,\n",
        "            'target_text': target_text\n",
        "        }\n",
        "\n",
        "# Causal mask will make sure any token that comes after the current token will be masked meaning the value will be replaced by -infinity that will be converted to zero or neearly zero after softmax operation. Hence the model will just ignore these value or willn't be able to learn anything.\n",
        "def causal_mask(size):\n",
        "        # Creating a square matrix of dimensions 'size x size' filled with ones\n",
        "        mask = torch.triu(torch.ones(1, size, size), diagonal = 1).type(torch.int)\n",
        "        return mask == 0\n",
        "\n",
        "# create a dataloader to use for model training and validation\n",
        "train_ds = EncodeDataset(raw_train_dataset, max_seq_len)\n",
        "val_ds = EncodeDataset(raw_validation_dataset, max_seq_len)\n",
        "\n",
        "train_dataloader = DataLoader(train_ds, batch_size = 5, shuffle = True)\n",
        "val_dataloader = DataLoader(val_ds, batch_size = 1, shuffle = True)"
      ],
      "metadata": {
        "id": "aj2sxENzXHtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "#  Input embedding and positional encoding\n",
        "class EmbeddingLayer(nn.Module):\n",
        "    def __init__(self, d_model: int, vocab_size: int):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        # using pytorch models embedding layer to map token id to embedding vector which has the shape of (vocab_size, d_model)\n",
        "        # The vocab_size is the vocabulary size of the training data created by tokenizer in step 2\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # In addition of giving input to the embedding, the extra multiplication by square root of d_model is to normalize the embedding layer output\n",
        "        embedding_output = self.embedding(input) * math.sqrt(self.d_model)\n",
        "        return embedding_output\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, max_seq_len: int, dropout_rate: float):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "\n",
        "        pos = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
        "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
        "\n",
        "        # since we're expecting the input sentences in batches so the extra dimension to cater batch number needs to be added in 0 postion\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, input_embdding):\n",
        "        input_embdding = input_embdding + (self.pe[:, :input_embdding.shape[1], :]).requires_grad_(False)   # to prevent from calculating gradient\n",
        "        return self.dropout(input_embdding)\n",
        "\n",
        "#  Multihead Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model: int, num_heads: int, dropout_rate: float):\n",
        "        super().__init__()\n",
        "        # Defining dropout to prevent overfitting\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.num_heads = num_heads\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by number of heads\"\n",
        "\n",
        "        # d_k is the new dimension of each self attention heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        # Weight matrix are defined which are all learnable parameters\n",
        "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.W_k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.W_v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.W_o = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "    def forward(self, q, k, v, encoder_mask):\n",
        "\n",
        "        # Please note that we'll be training our model with not just a single sequence but rather batches of sequence, hence we'll include batch_size in the shape\n",
        "        # query, Key and value are calculated by matrix multiplication of corresponding weights with the input embeddings\n",
        "        # Change of shape: q(batch_size, seq_len, d_model) @ W_q(d_model, d_model) => query(batch_size, seq_len, d_model) [same goes to key and value]\n",
        "        query = self.W_q(q)\n",
        "        key = self.W_k(k)\n",
        "        value = self.W_v(v)\n",
        "\n",
        "        # Dividing query, key and value into number of heads, hence new dimenstion will be d_k.\n",
        "        # Change of shape: query(batch_size, seq_len, d_model) => query(batch_size, seq_len, num_heads, d_k) -> query(batch_size,num_heads, seq_len,d_k) [same goes to key and value]\n",
        "        query = query.view(query.shape[0], query.shape[1], self.num_heads ,self.d_k).transpose(1,2)\n",
        "        key = key.view(key.shape[0], key.shape[1], self.num_heads ,self.d_k).transpose(1,2)\n",
        "        value = value.view(value.shape[0], value.shape[1], self.num_heads ,self.d_k).transpose(1,2)\n",
        "\n",
        "        # :: SELF ATTENTION BLOCK STARTS ::\n",
        "\n",
        "        # Attention score is calculated to find the similarity or relation of query with key of itself and all other embedding in the sequence\n",
        "        #  Change of shape: query(batch_size,num_heads, seq_len,d_k) @ key(batch_size,num_heads, seq_len,d_k) => attention_score(batch_size,num_heads, seq_len,seq_len)\n",
        "        attention_score = (query @ key.transpose(-2,-1))/math.sqrt(self.d_k)\n",
        "\n",
        "        # If mask is provided the attention score needs to modify as per the mask value. Refer to the details in point no 4.\n",
        "        if encoder_mask is not None:\n",
        "          attention_score.masked_fill_(encoder_mask==0, -1e9)\n",
        "\n",
        "        # Softmax operation calculates the probability distribution among all the attention scores. This will determine which embedding is more similar to the given query embedding and assign the attention weight accordingly.\n",
        "        # Change of shape: same as attention_score\n",
        "        attention_score = attention_score.softmax(dim=-1)\n",
        "\n",
        "        if self.dropout is not None:\n",
        "          attention_score = self.dropout(attention_score)\n",
        "\n",
        "        # Final step of Self attention block is to matrix multiplication of attention_weight with value embedding.\n",
        "        # Change of shape: attention_score(batch_size,num_heads, seq_len,seq_len) @  value(batch_size,num_heads, seq_len,d_k) => attention_output(batch_size,num_heads, seq_len,d_k)\n",
        "        attention_output = attention_score @ value\n",
        "\n",
        "        # :: SELF ATTENTION BLOCK ENDS ::\n",
        "\n",
        "        # Now, all the heads will be concated back to for a single head\n",
        "        # Change of shape:attention_output(batch_size,num_heads, seq_len,d_k) => attention_output(batch_size,seq_len,num_heads,d_k) => attention_output(batch_size,seq_len,d_model)\n",
        "        attention_output = attention_output.transpose(1,2).contiguous().view(attention_output.shape[0], -1, self.num_heads * self.d_k)\n",
        "\n",
        "        # Finally attention_output is matrix multiplied with output weight matrix to give the final Multi-Head attention output.\n",
        "        # The shape of the multihead_output is same as the embedding input\n",
        "        # Change of shape: attention_output(batch_size,seq_len,d_model) @ W_o(d_model, d_model) => multihead_output(batch_size, seq_len, d_model)\n",
        "        multihead_output = self.W_o(attention_output)\n",
        "\n",
        "        return multihead_output\n",
        "\n",
        "#  Feedfoward Network, Layer Normalization and AddAndNorm\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model: int, d_ff: int, dropout_rate: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.layer_1 = nn.Linear(d_model, d_ff)\n",
        "        self.layer_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.layer_2(self.dropout(torch.relu(self.layer_1(input))))\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    # def __init__(self, features:int=512, eps: float = 1e-5):\n",
        "    def __init__(self, eps: float = 1e-5):\n",
        "        super().__init__()\n",
        "        # epsilon is a very small value and is plays an important role to avoid division by zero problem\n",
        "        self.eps = eps\n",
        "        #Extra learning parameters gamma and beta are introduced to scale and shift the embedding value as the network needed.\n",
        "        self.gamma = nn.Parameter(torch.ones(512))  # 512 = advisable to initialize with same number as d_model\n",
        "        self.beta = nn.Parameter(torch.zeros(512))\n",
        "\n",
        "    def forward(self, input):\n",
        "        mean = input.mean(dim = -1, keepdim=True)\n",
        "        std = input.std(dim = -1, keepdim=True)\n",
        "        return self.gamma * (input - mean)/(std + self.eps) + self.beta\n",
        "\n",
        "class AddAndNorm(nn.Module):\n",
        "  def __init__(self, dropout_rate: float):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.layer_norm = LayerNorm()\n",
        "\n",
        "  def forward(self, input, sub_layer):\n",
        "        return input + self.dropout(sub_layer(self.layer_norm(input)))\n",
        "\n",
        "# Encoder block and Encoder\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    # def __init__(self, features: int, self_attention_block: MultiHeadAttention, feed_forward_block: FeedForward, dropout_rate: float) -> None:\n",
        "    def __init__(self, multihead_attention: MultiHeadAttention, feed_forward: FeedForward, dropout_rate: float) -> None:\n",
        "        super().__init__()\n",
        "        self.multihead_attention = multihead_attention\n",
        "        self.feed_forward = feed_forward\n",
        "        self.addnorm_1 = AddAndNorm(dropout_rate)\n",
        "        self.addnorm_2 = AddAndNorm(dropout_rate)\n",
        "\n",
        "    def forward(self, encoder_input, encoder_mask):\n",
        "        # First AddAndNorm unit taking encoder input from skip connection and adding it with the output of MultiHead attention block\n",
        "        encoder_input = self.addnorm_1(encoder_input, lambda encoder_input: self.multihead_attention(encoder_input, encoder_input, encoder_input, encoder_mask))\n",
        "        # Second AddAndNorm unit taking output of MultiHead attention block from skip connection and adding it with the output of Feedforward layer\n",
        "        encoder_input = self.addnorm_2(encoder_input, self.feed_forward)\n",
        "        return encoder_input\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, encoderblocklist: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        # Encoder class initialized by taking encoderblock list\n",
        "        self.encoderblocklist = encoderblocklist\n",
        "        self.layer_norm = LayerNorm()\n",
        "\n",
        "    def forward(self, encoder_input, encoder_mask):\n",
        "        # Looping through all the encoder block - 6 times\n",
        "        for encoderblock in self.encoderblocklist:\n",
        "            encoder_input = encoderblock(encoder_input, encoder_mask)\n",
        "        # Normalize the final encoder block output and return. This encoder output will be used later on as key and value for the cross attention in decoder block\n",
        "        encoder_output = self.layer_norm(encoder_input)\n",
        "        return encoder_output\n",
        "\n",
        "# Decoder block and decoder and the projection\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    # def __init__(self, features: int, self_attention_block: MultiHeadAttention, cross_attention_block: MultiHeadAttention, feed_forward_block: FeedForward, dropout_rate: float) -> None:\n",
        "    def __init__(self, masked_multihead_attention: MultiHeadAttention, cross_multihead_attention: MultiHeadAttention, feed_forward: FeedForward, dropout_rate: float) -> None:\n",
        "        super().__init__()\n",
        "        self.masked_multihead_attention = masked_multihead_attention\n",
        "        self.cross_multihead_attention = cross_multihead_attention\n",
        "        self.feed_forward = feed_forward\n",
        "        self.addnorm_1 = AddAndNorm(dropout_rate)\n",
        "        self.addnorm_2 = AddAndNorm(dropout_rate)\n",
        "        self.addnorm_3 = AddAndNorm(dropout_rate)\n",
        "\n",
        "    def forward(self, decoder_input, encoder_output, encoder_mask, decoder_mask):\n",
        "        # First AddAndNorm unit taking decoder input from skip connection and adding it with the output of Masked Multi-Head attention block\n",
        "        decoder_input = self.addnorm_1(decoder_input, lambda decoder_input: self.masked_multihead_attention(decoder_input, decoder_input, decoder_input, decoder_mask))\n",
        "        # Second AddAndNorm unit taking output of Masked Multi-Head attention block from skip connection and adding it with the output of MultiHead attention block\n",
        "        decoder_input = self.addnorm_2(decoder_input, lambda decoder_input: self.cross_multihead_attention(decoder_input, encoder_output, encoder_output, encoder_mask))\n",
        "        # Third AddAndNorm unit taking output of MultiHead attention block from skip connection and adding it with the output of Feedforward layer\n",
        "        decoder_input = self.addnorm_3(decoder_input, self.feed_forward)\n",
        "        return decoder_input\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    # def __init__(self, features: int, layers: nn.ModuleList) -> None:\n",
        "    def __init__(self, decoderblocklist: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.decoderblocklist = decoderblocklist\n",
        "        self.layer_norm = LayerNorm()\n",
        "\n",
        "    def forward(self, decoder_input, encoder_output, encoder_mask, decoder_mask):\n",
        "        for decoderblock in self.decoderblocklist:\n",
        "            decoder_input = decoderblock(decoder_input, encoder_output, encoder_mask, decoder_mask)\n",
        "        decoder_output = self.layer_norm(decoder_input)\n",
        "        return decoder_output\n",
        "\n",
        "class ProjectionLayer(nn.Module):\n",
        "    def __init__(self, d_model, vocab_size) -> None:\n",
        "        super().__init__()\n",
        "        self.projection_layer = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, decoder_output) -> None:\n",
        "        # Projection layer first take in decoder output and feed into the linear layer of shape (d_model, vocab_size)\n",
        "        #Change in shape: decoder_output(batch_size, seq_len, d_model) @ linear_layer(d_model, vocab_size) => output(batch_size, seq_len, vocab_size)\n",
        "        output = self.projection_layer(decoder_output)\n",
        "        return output\n",
        "\n",
        "# Create and build Transfomer\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder: Encoder, decoder: Decoder, source_embed: EmbeddingLayer, target_embed: EmbeddingLayer, source_pos: PositionalEncoding, target_pos: PositionalEncoding, projection_layer: ProjectionLayer) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.source_embed = source_embed\n",
        "        self.source_pos = source_pos\n",
        "        self.encoder = encoder\n",
        "\n",
        "        self.target_embed = target_embed\n",
        "        self.target_pos = target_pos\n",
        "        self.decoder = decoder\n",
        "\n",
        "        self.projection_layer = projection_layer\n",
        "\n",
        "    def encode(self, encoder_input, encoder_mask):\n",
        "        encoder_input = self.source_embed(encoder_input)\n",
        "        encoder_input = self.source_pos(encoder_input)\n",
        "        encoder_output = self.encoder(encoder_input, encoder_mask)\n",
        "        return encoder_output\n",
        "\n",
        "    def decode(self, encoder_output, encoder_mask, decoder_input, decoder_mask):\n",
        "        decoder_input = self.target_embed(decoder_input)\n",
        "        decoder_input = self.target_pos(decoder_input)\n",
        "        decoder_output = self.decoder(decoder_input, encoder_output, encoder_mask, decoder_mask)\n",
        "        return decoder_output\n",
        "\n",
        "    def project(self, decoder_output):\n",
        "        return self.projection_layer(decoder_output)\n",
        "\n",
        "def build_model(source_vocab_size: int, target_vocab_size: int, source_seq_len: int, target_seq_len: int, d_model: int=512, num_blocks: int=6, num_heads: int=8, dropout_rate: float=0.1, d_ff: int=2048) -> Transformer:\n",
        "    # Create the embedding layers\n",
        "    source_embed = EmbeddingLayer(d_model, source_vocab_size)\n",
        "    target_embed = EmbeddingLayer(d_model, target_vocab_size)\n",
        "\n",
        "    # Create the positional encoding layers\n",
        "    source_pos = PositionalEncoding(d_model, source_seq_len, dropout_rate)\n",
        "    target_pos = PositionalEncoding(d_model, target_seq_len, dropout_rate)\n",
        "\n",
        "    # Create the encoder-block-list\n",
        "    encoderblocklist = []\n",
        "    for _ in range(num_blocks):\n",
        "        multihead_attention = MultiHeadAttention(d_model, num_heads, dropout_rate)\n",
        "        feed_forward = FeedForward(d_model, d_ff, dropout_rate)\n",
        "        encoder_block = EncoderBlock(multihead_attention, feed_forward, dropout_rate)\n",
        "        encoderblocklist.append(encoder_block)\n",
        "    # Create the encoder\n",
        "    encoder = Encoder(nn.ModuleList(encoderblocklist))\n",
        "\n",
        "    # Create the decoder-block-list\n",
        "    decoderblocklist = []\n",
        "    for _ in range(num_blocks):\n",
        "        masked_multihead_attention = MultiHeadAttention(d_model,num_heads, dropout_rate)\n",
        "        cross_multihead_attention = MultiHeadAttention(d_model, num_heads, dropout_rate)\n",
        "        feed_forward = FeedForward(d_model, d_ff, dropout_rate)\n",
        "        decoder_block = DecoderBlock(masked_multihead_attention, cross_multihead_attention, feed_forward, dropout_rate)\n",
        "        decoderblocklist.append(decoder_block)\n",
        "    # Create the decoder\n",
        "    decoder = Decoder(nn.ModuleList(decoderblocklist))\n",
        "\n",
        "    # Create the projection layer\n",
        "    projection_layer = ProjectionLayer(d_model, target_vocab_size)\n",
        "\n",
        "    # Now that we've initialized all the required blocks of transformer, we can now inititiate a model\n",
        "    model = Transformer(encoder, decoder, source_embed, target_embed, source_pos, target_pos, projection_layer)\n",
        "\n",
        "    # For the first time, we'll initialize the model parameters using xavier uniform method. Once training begings the parameters will be updated by the network\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "BmsWyoWlXIAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Let's build the model.\n",
        "model = build_model(tokenizer_en.get_vocab_size(), tokenizer_my.get_vocab_size(),max_seq_len, max_seq_len, d_model=512).to(device)\n",
        "\n",
        "# Let's look at the architecture that we've just build ourself\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I511ToBzXIMP",
        "outputId": "f48726ca-855f-4316-da10-aefab6e28273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer(\n",
            "  (source_embed): EmbeddingLayer(\n",
            "    (embedding): Embedding(1308, 512)\n",
            "  )\n",
            "  (source_pos): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): Encoder(\n",
            "    (encoderblocklist): ModuleList(\n",
            "      (0-5): 6 x EncoderBlock(\n",
            "        (multihead_attention): MultiHeadAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): FeedForward(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (layer_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (addnorm_1): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "        (addnorm_2): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "  )\n",
            "  (target_embed): EmbeddingLayer(\n",
            "    (embedding): Embedding(1334, 512)\n",
            "  )\n",
            "  (target_pos): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (decoderblocklist): ModuleList(\n",
            "      (0-5): 6 x DecoderBlock(\n",
            "        (masked_multihead_attention): MultiHeadAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (cross_multihead_attention): MultiHeadAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): FeedForward(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (layer_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (addnorm_1): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "        (addnorm_2): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "        (addnorm_3): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "  )\n",
            "  (projection_layer): ProjectionLayer(\n",
            "    (projection_layer): Linear(in_features=512, out_features=1334, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(\"./Yorubagpt\")"
      ],
      "metadata": {
        "id": "MMC8_mT1WeuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "metadata": {
        "id": "eLgW68cfYAmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
      ],
      "metadata": {
        "id": "6Re_6pJnL-wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_validation(model, validation_ds, tokenizer_en, tokenizer_my, max_seq_len, device, print_msg, global_step):\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    reference_texts = []\n",
        "    generated_texts = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_ds:\n",
        "            count += 1\n",
        "            encoder_input = batch[\"encoder_input\"].to(device)\n",
        "            encoder_mask = batch[\"encoder_mask\"].to(device)\n",
        "\n",
        "            cls_id = tokenizer_my.token_to_id('[CLS]')\n",
        "            sep_id = tokenizer_my.token_to_id('[SEP]')\n",
        "\n",
        "            # Computing the output of the encoder for the source sequence\n",
        "            encoder_output = model.encode(encoder_input, encoder_mask)\n",
        "            # for prediction task, the first token that goes in decoder input is the [CLS] token\n",
        "            decoder_input = torch.empty(1, 1).fill_(cls_id).type_as(encoder_input).to(device)\n",
        "            # since we need to keep adding the output back to the input until the [SEP] - end token is received.\n",
        "            while True:\n",
        "                # check if the max length is received\n",
        "                if decoder_input.size(1) == max_seq_len:\n",
        "                    break\n",
        "\n",
        "                # recreate mask each time the new output is added the decoder input for next token prediction\n",
        "                decoder_mask = causal_mask(decoder_input.size(1)).type_as(encoder_mask).to(device)\n",
        "\n",
        "                # apply projection only to the next token\n",
        "                out = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
        "\n",
        "                # apply projection only to the next token\n",
        "                prob = model.project(out[:, -1])\n",
        "\n",
        "                # select the token with highest probablity which is a greedy search implementation\n",
        "                _, next_word = torch.max(prob, dim=1)\n",
        "                decoder_input = torch.cat(\n",
        "                    [decoder_input, torch.empty(1, 1).type_as(encoder_input).fill_(next_word.item()).to(device)], dim=1\n",
        "                )\n",
        "                # check if the new token is the end of token\n",
        "                if next_word == sep_id:\n",
        "                    break\n",
        "            # final output is the concatinated decoder input till the end token is reached\n",
        "            model_out = decoder_input.squeeze(0)\n",
        "\n",
        "            source_text = batch[\"source_text\"][0]\n",
        "            target_text = batch[\"target_text\"][0]\n",
        "            model_out_text = tokenizer_my.decode(model_out.detach().cpu().numpy())\n",
        "\n",
        "            reference_texts.append(target_text)\n",
        "            generated_texts.append(model_out_text)\n",
        "\n",
        "            # Print the source, target and model output\n",
        "            print_msg('-'*55)\n",
        "            print_msg(f'Source Text: {source_text}')\n",
        "            print_msg(f'Target Text: {target_text}')\n",
        "            print_msg(f'Predicted by YorubaGPT: {model_out_text}')\n",
        "\n",
        "            if count == 2:\n",
        "                break\n",
        "\n",
        "    # Compute BLEU score\n",
        "    bleu_score = compute_bleu_score(reference_texts, generated_texts)\n",
        "    #smoothing_function = SmoothingFunction().method1\n",
        "    #bleu_score = sentence_bleu(reference_texts, generated_texts, smoothing_function=smoothing_function)\n",
        "    print_msg(f'BLEU score: {bleu_score:.4f}')\n",
        "\n",
        "def compute_bleu_score(reference_texts, generated_texts):\n",
        "    \"\"\"\n",
        "    Compute the BLEU score for a list of reference texts and generated texts.\n",
        "\n",
        "    :param reference_texts: List of reference texts (ground truth)\n",
        "    :param generated_texts: List of generated texts by the model\n",
        "    :return: BLEU score\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    for ref, gen in zip(reference_texts, generated_texts):\n",
        "        ref_tokens = ref.split()  # Tokenize reference text\n",
        "        gen_tokens = gen.split()  # Tokenize generated text\n",
        "        scores.append(sentence_bleu([ref_tokens], gen_tokens))\n",
        "\n",
        "    return sum(scores) / len(scores) if scores else 0\n",
        "\n",
        "def train_model(preload_epoch=None):\n",
        "    # The entire training, validation cycle will run for 60 cycles or epochs.\n",
        "    EPOCHS = 150\n",
        "    initial_epoch = 0\n",
        "    global_step = 0\n",
        "\n",
        "    # Adam is one of the most commonly used optimization algorithms that hold the current state and will update the parameters based on the computed gradients.\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, eps=1e-9)\n",
        "\n",
        "    # If the preload_epoch is not none, that means the training will start with the weights, optimizer that has been last saved and start with preload epoch + 1\n",
        "    if preload_epoch is not None:\n",
        "      model_filename = f\"./Yorubagpt/model_{preload_epoch}.pt\"\n",
        "      state = torch.load(model_filename)\n",
        "      model.load_state_dict(state['model_state_dict'])\n",
        "      initial_epoch = state['epoch'] + 1\n",
        "      optimizer.load_state_dict(state['optimizer_state_dict'])\n",
        "      global_step = state['global_step']\n",
        "\n",
        "    # The CrossEntropyLoss loss function computes the difference between the projection output and target label.\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_en.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
        "\n",
        "    for epoch in range(initial_epoch, EPOCHS):\n",
        "        # torch.cuda.empty_cache()\n",
        "        model.train()\n",
        "        batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n",
        "        for batch in batch_iterator:\n",
        "            encoder_input = batch['encoder_input'].to(device) # (b, seq_len)\n",
        "            decoder_input = batch['decoder_input'].to(device) # (B, seq_len)\n",
        "            encoder_mask = batch['encoder_mask'].to(device) # (B, 1, 1, seq_len)\n",
        "            decoder_mask = batch['decoder_mask'].to(device) # (B, 1, seq_len, seq_len)\n",
        "            target_label = batch['target_label'].to(device) # (B, seq_len)\n",
        "\n",
        "            # Run the tensors through the encoder, decoder and the projection layer\n",
        "            encoder_output = model.encode(encoder_input, encoder_mask) # (B, seq_len, d_model)\n",
        "            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask) # (B, seq_len, d_model)\n",
        "            projection_output = model.project(decoder_output) # (B, seq_len, vocab_size)\n",
        "\n",
        "            # Compute the loss using a simple cross entropy\n",
        "            loss = loss_fn(projection_output.view(-1, tokenizer_my.get_vocab_size()), target_label.view(-1))\n",
        "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
        "\n",
        "            # Backpropagate the loss\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the weights\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        # VALIDATION BLOCK STARTS HERE [Runs every epoch after the training block is complete]\n",
        "        run_validation(model, val_dataloader, tokenizer_en, tokenizer_my, max_seq_len, device, lambda msg: batch_iterator.write(msg), global_step)\n",
        "\n",
        "        # Save the model at the end of every epoch\n",
        "        model_filename = f\"./Yorubagpt/model_{epoch}.pt\"\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'global_step': global_step\n",
        "        }, model_filename)\n"
      ],
      "metadata": {
        "id": "bP9ppPvn-okt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nGk_g_SpLeM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train our model\n",
        "train_model(preload_epoch=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "im5SwFdYYWs6",
        "outputId": "1f1bd809-f864-4ea4-8c28-0aa387d2da9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 00: 100%|██████████| 222/222 [00:33<00:00,  6.67it/s, loss=4.875]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ẹ máa tà á jálẹ̀jálẹ̀?\n",
            "Target Text: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀?\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún náírà ni náírà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Àwọn rèé:  orí màlúù kan, awọ, ẹsẹ̀, àti orí àgbò.\n",
            "Target Text: orí màlúù kan, ẹsẹ̀ mẹ́rin, ìrù màlúù àti orí àgbò márùn-ún.\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "Processing Epoch 01: 100%|██████████| 222/222 [00:31<00:00,  7.05it/s, loss=3.705]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Kò dín?\n",
            "Target Text: Kò dín rárá. Iye tí à ń sún wọ́n nì yẹn.\n",
            "Predicted by YorubaGPT: O dara , o jẹ ẹgbẹrun mẹta naira .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ẹ pè é?\n",
            "Target Text: Ọgọ́rùn-ún méjì náírà.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún náírà ni .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 02: 100%|██████████| 222/222 [00:31<00:00,  6.97it/s, loss=1.413]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Mo fẹ́ kí ẹ bá mi sún àwọn nǹkan kan ni\n",
            "Target Text: Àwọn nǹkan wo?\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣé ẹ ò fẹ́ kí a di oníbàárà ni?\n",
            "Target Text: Kò rí bẹ́ẹ̀. Nǹkan ló wọ́n.\n",
            "Predicted by YorubaGPT: Bẹẹni , a ni ẹrọ mọnamọna to dara .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 03: 100%|██████████| 222/222 [00:31<00:00,  7.07it/s, loss=2.513]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ jẹ́ kí a san ogọ́rùn-ún márùn-ún àti àádọ́ta náírà (N550).ọgọ́rùn-ún náírà, àwa náà a lè jẹ èrè àádọ́ta náírà.\n",
            "Target Text: Àpò mélòó ni ẹ fẹ́?\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ọ̀rá Santana tí wọ́n ń pè ní ‘Abiola’?\n",
            "Target Text: Soji ni àwa ń pè é níbí. Ọgọ́rin náírà péré ni.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún náírà .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 04: 100%|██████████| 222/222 [00:31<00:00,  7.06it/s, loss=4.229]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ tà á fún mi bẹ́ẹ̀, ṣe bí oníbàárà yín ni mí.\n",
            "Target Text: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀?\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ seun.\n",
            "Target Text: A dúpẹ́.\n",
            "Predicted by YorubaGPT: Ó dàbọ̀ .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 05: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.717]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ṣé eleyìí dùn?\n",
            "Target Text: Se kii di fun yin\n",
            "Predicted by YorubaGPT: Bẹẹni , a ni agbada tuntun ti o dara .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni eléyìí?\n",
            "Target Text: Ọgọ́rùn-ún náírà ni!\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún méjì náírà ni .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 06: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=3.065]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Hajiya, ẹran eélòó ni ẹ fẹ́ rà?\n",
            "Target Text: Ọgọ́rùn-ún márùn-ún náírà..\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ọlọ́run á sọ òde dẹ̀rọ̀. Ẹ mún ún wá bẹ́ẹ̀.\n",
            "Target Text: Òhun rè é!\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 07: 100%|██████████| 222/222 [00:31<00:00,  6.99it/s, loss=1.469]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Kí lẹ fẹ́ dì? Ọgọ́rùn-ún náírà ti wọ́n jù.\n",
            "Target Text: Èwo?\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa. Ẹ seun.\n",
            "Target Text: A dúpẹ́\n",
            "Predicted by YorubaGPT: Ó dàbọ̀ .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 08: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=1.097]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ṣé èyí ni wọ́n ń tà ní ẹgbẹ̀rún kan àti ọgọ́rùn-ún mẹ́ta náírà?\n",
            "Target Text: Bẹ́ẹ̀ni, ẹgbẹ̀rún kan àti ọgọ́rùn-ún mẹ́ta náírà ni.\n",
            "Predicted by YorubaGPT: Bẹ́ẹ̀ni , ó wà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣé eleyìí dùn?\n",
            "Target Text: Se kii di fun yin\n",
            "Predicted by YorubaGPT: Bẹ́ẹ̀ni . Kí lẹ fẹ́ẹ́ mọ̀ ?\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 09: 100%|██████████| 222/222 [00:31<00:00,  7.05it/s, loss=1.561]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ọgọ́rùn-ún mẹ́fà náírà ni màá san. Ṣé kì ń san owó?\n",
            "Target Text: Ẹhn, ẹ mú owó wá.\n",
            "Predicted by YorubaGPT: Ẹ san ọgọ́rùn - ún márùn - ún àti àádọ́ta naira .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣé ẹ ò fẹ́ kí a di oníbàárà ni?\n",
            "Target Text: Kò rí bẹ́ẹ̀. Nǹkan ló wọ́n.\n",
            "Predicted by YorubaGPT: Kò si , ṣùgbọ́n jálẹ̀jálẹ̀ nì yẹn .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 10: 100%|██████████| 222/222 [00:31<00:00,  7.01it/s, loss=1.409]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ṣé kí ń san àádọ́ta náírà fún méjì?\n",
            "Target Text: Ó tì.\n",
            "Predicted by YorubaGPT: Ó tì .\n",
            "-------------------------------------------------------\n",
            "Source Text: Onikunu, ẹ fún mi ní kunu.\n",
            "Target Text: Eléélòó ni?\n",
            "Predicted by YorubaGPT: E lé élòó ni ?\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 11: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.571]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Mo fẹ́ ra Magi.\n",
            "Target Text: Maggi nìkan?\n",
            "Predicted by YorubaGPT: Ṣé ẹ fẹ́ ẹ̀ dọ̀ ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni kóńgò ẹ̀pà?\n",
            "Target Text: Ọgọ́ta náírà.\n",
            "Predicted by YorubaGPT: Ọgọ́ta náírà .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 12: 100%|██████████| 222/222 [00:31<00:00,  7.00it/s, loss=1.220]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni kilo inú ẹran?\n",
            "Target Text: Ẹgbẹ̀rún náírà ni kílò.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún méjì náírà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ẹ ń ta ìgbá?\n",
            "Target Text: Eléyi jẹ́ ọgọ́fà náírà, ìyẹ́n jẹ́ Àádọ́ta náírà.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún méjì náírà .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 13: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=1.298]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Alhaji, ṣé ajé ń wọgbá?\n",
            "Target Text: A dúpẹ́\n",
            "Predicted by YorubaGPT: A dúpẹ́\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ dì í pọ̀ bí ẹ ṣe máa ń ṣe é.\n",
            "Target Text: Ó dáa.\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 14: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=1.495]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ṣé kí ń san àádọ́ta náírà fún méjì?\n",
            "Target Text: Ó tì.\n",
            "Predicted by YorubaGPT: Ó tì .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ẹ ń ta a ẹyọ?\n",
            "Target Text: Àádọ́ta náírà ni ẹyọ.\n",
            "Predicted by YorubaGPT: Àádọ́ta náírà ni ẹyọ .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 15: 100%|██████████| 222/222 [00:31<00:00,  6.99it/s, loss=1.202]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ẹ máa tà á jálẹ̀jálẹ̀?\n",
            "Target Text: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀?\n",
            "Predicted by YorubaGPT: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀ ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni eléyìí?\n",
            "Target Text: Ọgọ́rùn-ún náírà ni!\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún náírà ni !\n",
            "BLEU score: 0.3402\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 16: 100%|██████████| 222/222 [00:31<00:00,  7.01it/s, loss=1.434]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa, ẹ fún mi ní aláàádọ́ta náírà.\n",
            "Target Text: Ó dáa.\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa, ẹ fún mi ní kóńgò méjì!\n",
            "Target Text: Ó dáa.\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 17: 100%|██████████| 222/222 [00:31<00:00,  7.00it/s, loss=1.422]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ fún mi ní àgbọn ogún náírà àti date ogún náírà.\n",
            "Target Text: Ó dáa. Òun rèé!\n",
            "Predicted by YorubaGPT: Ó dáa . Òun rèé !\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ tà á fún mi bẹ́ẹ̀, ṣe bí oníbàárà yín ni mí.\n",
            "Target Text: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀?\n",
            "Predicted by YorubaGPT: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀ ?\n",
            "BLEU score: 0.3402\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 18: 100%|██████████| 222/222 [00:31<00:00,  7.00it/s, loss=1.207]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Onikunu, ẹ fún mi ní kunu.\n",
            "Target Text: Eléélòó ni?\n",
            "Predicted by YorubaGPT: E lé élòó ni ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Kò dín?\n",
            "Target Text: Kò dín rárá. Iye tí à ń sún wọ́n nì yẹn.\n",
            "Predicted by YorubaGPT: Kò dín rárá . Iye tí à ń s ún wọ́n nì yẹn .\n",
            "BLEU score: 0.1201\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 19: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.365]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ fi í sílẹ̀ fún mi bẹ́ẹ̀.\n",
            "Target Text: Ẹ jọ̀ọ́, mi ò lè tà á bẹ́ẹ̀.\n",
            "Predicted by YorubaGPT: Ẹ jọ̀ọ́ , mi ò lè tà á bẹ́ẹ̀ .\n",
            "-------------------------------------------------------\n",
            "Source Text: Kò dín?\n",
            "Target Text: Kò dín rárá. Iye tí à ń sún wọ́n nì yẹn.\n",
            "Predicted by YorubaGPT: Iye tí à ń gbé e nì yẹn . È rò mé lò o ́ ló ń lọ ?\n",
            "BLEU score: 0.2726\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 20: 100%|██████████| 222/222 [00:31<00:00,  7.00it/s, loss=1.079]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni èyí?\n",
            "Target Text: Ọgbọ̀n náírà.\n",
            "Predicted by YorubaGPT: Ọ gbọ̀n náírà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni jálẹ̀jálẹ̀?\n",
            "Target Text: Jálẹ̀jálẹ̀ nì yẹn.\n",
            "Predicted by YorubaGPT: B ẹ́ ẹ́ ẹ́ ẹ́ ẹ́ ẹ́ ẹ́ ẹ́ ẹ́ ẹ́ ẹ́ ẹ́ ẹ́ ẹ́ ẹ́ ẹ́ ẹ́ ni , ọgọ́rùn - ún méjì , ọgọ́rùn - ún méjì àti àádọ́ta náírà ni .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 21: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=1.076]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni jálẹ̀jálẹ̀?\n",
            "Target Text: Jálẹ̀jálẹ̀ nì yẹn.\n",
            "Predicted by YorubaGPT: Jálẹ̀jálẹ̀ nì yẹn .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni àgbàdo?\n",
            "Target Text: Àádọ́ta náírà ni àgbàdo.\n",
            "Predicted by YorubaGPT: Àádọ́ta náírà ni à gbà do .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 22: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=1.302]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni gúábà?\n",
            "Target Text: Èyí ọọ́rùn-ún náírà, ìyẹn ọgọ́ta.\n",
            "Predicted by YorubaGPT: Èyí ọ ọ́ rùn - ún náírà , ìyẹn ọgọ́ta\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ ǹlẹ́ o, Ọ̀gá.\n",
            "Target Text: Ẹ káàsán, sà.\n",
            "Predicted by YorubaGPT: Ẹ káàsán , sà .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 23: 100%|██████████| 222/222 [00:31<00:00,  6.97it/s, loss=1.179]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni jálẹ̀jálẹ̀?\n",
            "Target Text: Jálẹ̀jálẹ̀ nì yẹn.\n",
            "Predicted by YorubaGPT: Jálẹ̀jálẹ̀ nì yẹn .\n",
            "-------------------------------------------------------\n",
            "Source Text: Alánàmá, eélòó ni ànàmá?\n",
            "Target Text: Ọgọ́rùn-ún méjì náírà ni èyí.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún méjì náírà ni èyí .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 24: 100%|██████████| 222/222 [00:31<00:00,  7.01it/s, loss=1.233]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ ò lè dín in rárá?\n",
            "Target Text: Ẹgbẹ̀rún márùn-ún náírà ni iye-owó yín. Ẹgbẹ̀rún méjì-àbọ̀ náírà (N2500) lọ́nà méjì jásí ẹgbẹ̀rún márùn-ún náírà.\n",
            "Predicted by YorubaGPT: Ẹgbẹ̀rún márùn - ún náírà ni iye - owó yín . Ẹgbẹ̀rún méjì - àbọ̀ náírà lọ́nà méjì já sí ẹgbẹ̀rún márùn - ún náírà\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣùgbọ́n, ẹ lè gbàgbé àti fi ṣúgà sí i..\n",
            "Target Text: Ó dáa, màá bá ẹ fi ṣúgà sí i dáadáa.\n",
            "Predicted by YorubaGPT: Ó dáa , màá bá ẹ fi ṣúgà sí i dáadáa .\n",
            "BLEU score: 0.2666\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 25: 100%|██████████| 222/222 [00:31<00:00,  7.05it/s, loss=1.243]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni àwọn tó wà nínú abọ́ yìí?\n",
            "Target Text: Eléyìí jẹ́ Ọgọ́rùn-ún mẹ́ta náírà, èyí Ọgọ́rùn-ún márùn-ún náírà.\n",
            "Predicted by YorubaGPT: Eléyìí jẹ́ Ọgọ́rùn - ún mẹ́ta náírà , èyí Ọgọ́rùn - ún márùn - ún náírà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Bẹ́ẹ̀ni.\n",
            "Target Text: Kí ni ẹ tún fẹ́?\n",
            "Predicted by YorubaGPT: Kilo mélòó ?\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 26: 100%|██████████| 222/222 [00:31<00:00,  7.00it/s, loss=1.128]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ńlá.\n",
            "Target Text: Ọgọ́rùn-ún mẹ́rin náírà ni ńlá.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún mẹ́rin náírà ni ń lá .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ẹ máa tà á jálẹ̀jálẹ̀?\n",
            "Target Text: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀?\n",
            "Predicted by YorubaGPT: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀ ?\n",
            "BLEU score: 0.3402\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 27: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.184]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa. Ẹ seun. Owó rèé!\n",
            "Target Text: Ẹ seun o. \n",
            "Predicted by YorubaGPT: Ó dàbọ̀ .\n",
            "-------------------------------------------------------\n",
            "Source Text: Kò dín?\n",
            "Target Text: Kò dín rárá. Iye tí à ń sún wọ́n nì yẹn.\n",
            "Predicted by YorubaGPT: Kò dín rárá . Iye tí à ń s ún wọ́n nì yẹn .\n",
            "BLEU score: 0.1201\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 28: 100%|██████████| 222/222 [00:31<00:00,  7.00it/s, loss=1.320]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ṣé pé kò gbá Ọgọ́ta náírà?\n",
            "Target Text: Kò gbà.\n",
            "Predicted by YorubaGPT: Kò gbà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Bá wo ni ẹ ṣe ń tà á?\n",
            "Target Text: Bí ẹ bá ṣe fẹ́ ẹ sí ni. A ń ta oní- àádọ́ta náírà ogójì náírà àti ọgbọ̀n náírà.\n",
            "Predicted by YorubaGPT: Bí ẹ bá ṣe fẹ́ ẹ sí ni . A ń ta oní - àádọ́ta náírà ogójì náírà àti ọgbọ̀n náírà .\n",
            "BLEU score: 0.2683\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 29: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.212]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni páálí‘Tiara’?\n",
            "Target Text: Ẹgbẹ̀rún kan lé ní Ọgọ́rùn-ún náírà ni páálí tiara.\n",
            "Predicted by YorubaGPT: Ẹgbẹ̀rún kan lé ní Ọgọ́rùn - ún náírà ni páálí ti a ra .\n",
            "-------------------------------------------------------\n",
            "Source Text: Kí lẹ̀ ń sọ, ẹ̀yin kọ́ lẹ̀ ń tà á ni?\n",
            "Target Text:  Ṣé kí ń ta aláàádọ́ta náírà fún yín?\n",
            "Predicted by YorubaGPT: Ṣé kí n dì ?\n",
            "BLEU score: 0.1286\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 30: 100%|██████████| 222/222 [00:31<00:00,  6.98it/s, loss=1.191]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ fún mi ní àgbọn ogún náírà àti date ogún náírà.\n",
            "Target Text: Ó dáa. Òun rèé!\n",
            "Predicted by YorubaGPT: Ó dáa . Òun rèé !\n",
            "-------------------------------------------------------\n",
            "Source Text: Onígbàá, ṣé ajé ń wọgbá?\n",
            "Target Text: A dúpẹ́.\n",
            "Predicted by YorubaGPT: A dúpẹ́ lọ́wọ́ Ọlọ́run .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 31: 100%|██████████| 222/222 [00:31<00:00,  7.05it/s, loss=1.205]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Á hàá, ṣé iye tí ẹ fẹ́ẹ́ tà á nì yẹn?\n",
            "Target Text: Ọgọ́rùn-ún méjì àti àádọ́ta náírà ni jálẹ̀jálẹ̀.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún méjì àti àádọ́ta náírà ni jálẹ̀jálẹ̀ .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ẹ máa tà á jálẹ̀jálẹ̀?\n",
            "Target Text: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀?\n",
            "Predicted by YorubaGPT: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀ ?\n",
            "BLEU score: 0.5366\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 32: 100%|██████████| 222/222 [00:31<00:00,  6.99it/s, loss=1.157]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: N20 kẹ̀? Odindi ńkọ́?\n",
            "Target Text: Èwo?\n",
            "Predicted by YorubaGPT: Èwo ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣé kí ń san àádọ́ta náírà fún méjì?\n",
            "Target Text: Ó tì.\n",
            "Predicted by YorubaGPT: Ó tì .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 33: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=1.122]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni bọ́tà Simas?\n",
            "Target Text: àádóje náírà ni Bọ́tà Simas.\n",
            "Predicted by YorubaGPT: àád ó je náírà ni B ọ́ tà Si ma s .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni jálẹ̀jálẹ̀?\n",
            "Target Text: Ogójì náírà.\n",
            "Predicted by YorubaGPT: Ọ̀gá , iye ẹ̀ nì yẹn .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 34: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=1.131]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Á-hàá! Ọgọ́rùn-ún náírà kẹ̀?\n",
            "Target Text: Iye ẹ̀ nì yẹn.\n",
            "Predicted by YorubaGPT: Iye ẹ̀ nì yẹn .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣé kí ń san àádọ́ta náírà fún méjì?\n",
            "Target Text: Ó tì.\n",
            "Predicted by YorubaGPT: Ó tì .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 35: 100%|██████████| 222/222 [00:31<00:00,  7.05it/s, loss=1.447]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ọgọ́rùn-ún méje àti àádọ́ta náírà ni màá san.\n",
            "Target Text: Ó tì.\n",
            "Predicted by YorubaGPT: Ó tì .\n",
            "-------------------------------------------------------\n",
            "Source Text: Náírà mẹ́wàá kọ́ ni mo pè é. Bá wo ni ti ogún náírà ṣe kéré báyìí?\n",
            "Target Text: Gbogbo nǹkan ló mà ti wọ́n.\n",
            "Predicted by YorubaGPT: Gbogbo nǹkan ló mà ti wọ́n .\n",
            "BLEU score: 0.3074\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 36: 100%|██████████| 222/222 [00:31<00:00,  7.00it/s, loss=1.140]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Onikunu, ẹ fún mi ní kunu.\n",
            "Target Text: Eléélòó ni?\n",
            "Predicted by YorubaGPT: E lé élòó ni ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣé ẹ ò fẹ́ kí a di oníbàárà ni?\n",
            "Target Text: Kò rí bẹ́ẹ̀. Nǹkan ló wọ́n.\n",
            "Predicted by YorubaGPT: Kò rí bẹ́ẹ̀ . N ǹkan ló wọ́n .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 37: 100%|██████████| 222/222 [00:31<00:00,  7.05it/s, loss=1.086]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ ǹlẹ́ o, Baba.\n",
            "Target Text: Pẹ̀lẹ́ o.\n",
            "Predicted by YorubaGPT: Ẹ ǹlẹ́ o .\n",
            "-------------------------------------------------------\n",
            "Source Text: Bẹ́ẹ̀ni.\n",
            "Target Text: Kí ni ẹ tún fẹ́?\n",
            "Predicted by YorubaGPT: N220 .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 38: 100%|██████████| 222/222 [00:31<00:00,  7.00it/s, loss=1.163]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Á hàá, ṣé iye tí ẹ fẹ́ẹ́ tà á nì yẹn?\n",
            "Target Text: Ọgọ́rùn-ún méjì àti àádọ́ta náírà ni jálẹ̀jálẹ̀.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún méjì àti àádọ́ta náírà ni jálẹ̀jálẹ̀ .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ ǹlẹ́ o, Ọ̀gá.\n",
            "Target Text: Ẹ káàsán, sà.\n",
            "Predicted by YorubaGPT: Ẹ káàsán , sà .\n",
            "BLEU score: 0.1964\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 39: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.140]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Mo fẹ́ ra Magi.\n",
            "Target Text: Maggi nìkan?\n",
            "Predicted by YorubaGPT: Ma g i nìkan ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣé èyí ni wọ́n ń tà ní ẹgbẹ̀rún kan àti ọgọ́rùn-ún mẹ́ta náírà?\n",
            "Target Text: Bẹ́ẹ̀ni, ẹgbẹ̀rún kan àti ọgọ́rùn-ún mẹ́ta náírà ni.\n",
            "Predicted by YorubaGPT: Bẹ́ẹ̀ni\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 40: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=1.180]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ẹ pè é?\n",
            "Target Text: Ọgọ́rùn-ún méjì náírà.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún méjì náírà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ẹ ń ta date?  ẹ fún mi ní date ogún náírà àti àgbọn ogún náírà.\n",
            "Target Text: Ó dáa.\n",
            "Predicted by YorubaGPT: Ó dáa . Òun rèé !\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 41: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=1.071]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ṣé eléyìí tó kilo kan?\n",
            "Target Text: Kilo kan ni.\n",
            "Predicted by YorubaGPT: Kilo kan ni .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni jálẹ̀jálẹ̀?\n",
            "Target Text: Àádọ́rin náírà ni jálẹ̀jálẹ̀.\n",
            "Predicted by YorubaGPT: Jálẹ̀jálẹ̀ nì yẹn .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 42: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.108]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Kò dín?\n",
            "Target Text: Kò dín rárá. Iye tí à ń sún wọ́n nì yẹn.\n",
            "Predicted by YorubaGPT: Kò dín rárá . Iye tí à ń s ún wọ́n nì yẹn .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ọgọ́rùn-ún mẹ́fà náírà ni màá san. Ṣé kì ń san owó?\n",
            "Target Text: Ẹhn, ẹ mú owó wá.\n",
            "Predicted by YorubaGPT: Ẹ h n , ẹ mú owó wá .\n",
            "BLEU score: 0.1201\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 43: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.230]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ṣé ajé ń wọgbá?\n",
            "Target Text: A dúpẹ́ lọ́wọ́ Ọlọ́run.\n",
            "Predicted by YorubaGPT: Olúwa ṣeun .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ẹ pè é?\n",
            "Target Text: Ọgọ́rùn-ún méjì náírà.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún méjì náírà .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 44: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.198]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni jálẹ̀jálẹ̀?\n",
            "Target Text: Bẹ́ẹ́ni, ọgọ́rùn-ún méjì àti àádọ́ta náírà ni.\n",
            "Predicted by YorubaGPT: O gó jì náírà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa, eélòó ni jálẹ̀jálẹ̀?\n",
            "Target Text: Ẹgbẹ̀rún kan-àbọ̀ náírà ni à ń tà á.\n",
            "Predicted by YorubaGPT: Ẹgbẹ̀rún kan - àbọ̀ náírà ni à ń tà á .\n",
            "BLEU score: 0.1836\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 45: 100%|██████████| 222/222 [00:31<00:00,  7.05it/s, loss=1.145]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Àádọ́jọ́ náírà.\n",
            "Target Text: Mo nílò ohun-mímu ààbọ̀ agolo mílíìkì, ‘Nescafe’, ẹyin méjì àti búrẹ́dì ọgbọ̀n náírà. Eélòó ni gbogbo ẹ̀?\n",
            "Predicted by YorubaGPT: Mo nílò ohun - mí mu ààbọ̀ agolo mílíìkì , ‘ Nescafe ’ , ẹ yin méjì àti búr ẹ́ dì ọgbọ̀n náírà . Eélòó ni gbogbo ẹ̀ ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ jọ̀ọ́, ẹ wá fún wa ní Maggi!\n",
            "Target Text: Irú èwo ni ẹ fẹ́ rà?\n",
            "Predicted by YorubaGPT: Irú èwo ni ẹ fẹ́ rà ?\n",
            "BLEU score: 0.3074\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 46: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.194]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ọgọ́rùn-ún méje àti àádọ́ta náírà ni màá san.\n",
            "Target Text: Ó tì.\n",
            "Predicted by YorubaGPT: Ó tì .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ìdì kan ni. Eélòó ni yẹn?\n",
            "Target Text: Ẹgbẹ̀rún kan-àbọ̀ naira, ó lé àádọ́rin náírà (N1,570).\n",
            "Predicted by YorubaGPT: Ẹgbẹ̀rún kan - àbọ̀ naira , ó lé àádọ́rin náírà\n",
            "BLEU score: 0.1389\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 47: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=1.184]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ó dàbọ̀.\n",
            "Target Text: Ẹ seun.\n",
            "Predicted by YorubaGPT: Ó dàbọ̀ .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ jọ̀ọ́, mò ń kánjú. Àwọn ọmọ mi ń lọ sí ilé-ìwé láì pẹ́.\n",
            "Target Text: Bí ẹ ṣe ń ná an, èmi gan-an ò rí i rà bẹ́ẹ̀, ká má ì tíì sọ ti èrè.\n",
            "Predicted by YorubaGPT: Bí ẹ ṣe ń ná an , è mi gan - an ò rí i rà bẹ́ẹ̀ , ká má ì tíì sọ ti èrè .\n",
            "BLEU score: 0.2028\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 48: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=1.121]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ẹ ń ta?\n",
            "Target Text: Èyí àádọ́ta náírà, èyí ọgbọ̀n náírà.\n",
            "Predicted by YorubaGPT: Èyí àádọ́ta náírà , èyí ọgbọ̀n náírà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣé eleyìí dùn?\n",
            "Target Text: Se kii di fun yin\n",
            "Predicted by YorubaGPT: Bẹ́ẹ̀ni , mo ń bá wọn s ọ̀rọ̀ dáadáa .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 49: 100%|██████████| 222/222 [00:31<00:00,  7.06it/s, loss=1.105]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ fi ṣúgà sí i dáadáa.\n",
            "Target Text: Mi ò kí í po tíì láì sí ṣúgà.\n",
            "Predicted by YorubaGPT: Mi ò kí í po tíì lá ì sí ṣúgà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣé ẹ ò fẹ́ kí a di oníbàárà ni?\n",
            "Target Text: Kò rí bẹ́ẹ̀. Nǹkan ló wọ́n.\n",
            "Predicted by YorubaGPT: Kò rí bẹ́ẹ̀ . N ǹkan ló wọ́n .\n",
            "BLEU score: 0.2399\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 50: 100%|██████████| 222/222 [00:31<00:00,  7.05it/s, loss=1.055]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ dì í pọ̀ bí ẹ ṣe máa ń ṣe é.\n",
            "Target Text: Ó dáa.\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó tì.\n",
            "Target Text: Ẹ gbà. Ẹ seun o. Ó dàbọ̀.\n",
            "Predicted by YorubaGPT: Ẹ gbà . Ẹ seun o . Ó dàbọ̀ .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 51: 100%|██████████| 222/222 [00:31<00:00,  7.01it/s, loss=1.097]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni kóńgò ẹ̀pà?\n",
            "Target Text: Ọgọ́ta náírà.\n",
            "Predicted by YorubaGPT: Ọgọ́ta náírà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni jálẹ̀jálẹ̀?\n",
            "Target Text: Jálẹ̀jálẹ̀ nì yẹn.\n",
            "Predicted by YorubaGPT: Jálẹ̀jálẹ̀ nì yẹn .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 52: 100%|██████████| 222/222 [00:31<00:00,  6.99it/s, loss=1.136]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ẹ máa tà á jálẹ̀jálẹ̀?\n",
            "Target Text: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀?\n",
            "Predicted by YorubaGPT: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀ ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Ọgọ́fà náírà, ní ìgbà òjò yí?\n",
            "Target Text: Bẹ́ẹ̀ni, ọgọ́fà náírà ni. Ṣé kí n dì í?\n",
            "Predicted by YorubaGPT: Kò ṣ òro rárá láti dé Ọ̀ fà . Ọ̀ kan lá ra àwọn Ìdíkọ̀ wa tí ó gba jú gba jà ni Ọ̀ fà . Bí ọkọ̀ ojúurin bá ti gbéra ní Èkó , á dúró ní A b ẹ́ ò kú ta , Ì bà d àn àti Ò ṣ o gbo , ó di Ọ̀ f fà .\n",
            "BLEU score: 0.3402\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 53: 100%|██████████| 222/222 [00:31<00:00,  7.09it/s, loss=1.139]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Á hàá, ṣé iye tí ẹ fẹ́ẹ́ tà á nì yẹn?\n",
            "Target Text: Ọgọ́rùn-ún méjì àti àádọ́ta náírà ni jálẹ̀jálẹ̀.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún méjì àti àádọ́ta náírà ni jálẹ̀jálẹ̀ .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣé pé kò gbá Ọgọ́ta náírà?\n",
            "Target Text: Kò gbà.\n",
            "Predicted by YorubaGPT: Kò gbà .\n",
            "BLEU score: 0.1964\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 54: 100%|██████████| 222/222 [00:31<00:00,  7.01it/s, loss=1.063]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ fún mi ní àgbọn ogún náírà àti date ogún náírà.\n",
            "Target Text: Ó dáa. Òun rèé!\n",
            "Predicted by YorubaGPT: Ó dáa . Òun rèé !\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni jálẹ̀jálẹ̀?\n",
            "Target Text: Ọ̀gá, iye ẹ̀ nì yẹn.\n",
            "Predicted by YorubaGPT: Àádọ́rin náírà ni jálẹ̀jálẹ̀ .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 55: 100%|██████████| 222/222 [00:31<00:00,  7.06it/s, loss=1.126]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Alágbọn, Eélòó ni ègé àgbọn?\n",
            "Target Text: Ogún náírà.\n",
            "Predicted by YorubaGPT: Ogún náírà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa, ẹ seun.\n",
            "Target Text: Ẹ̀yin náà seun.\n",
            "Predicted by YorubaGPT: Ẹ̀yin náà seun .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 56: 100%|██████████| 222/222 [00:31<00:00,  7.06it/s, loss=1.196]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni àgbàdo?\n",
            "Target Text: Àádọ́ta náírà ni àgbàdo.\n",
            "Predicted by YorubaGPT: Àádọ́ta náírà ni à gbà do .\n",
            "-------------------------------------------------------\n",
            "Source Text: Alánàmá, eélòó ni ànàmá?\n",
            "Target Text: Ọgọ́rùn-ún méjì náírà ni èyí.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún méjì náírà ni èyí .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 57: 100%|██████████| 222/222 [00:31<00:00,  7.06it/s, loss=1.094]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ńlá.\n",
            "Target Text: Ọgọ́rùn-ún mẹ́rin náírà ni ńlá.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún mẹ́rin náírà ni ń lá .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ ǹlẹ́ o, Ọ̀gá.\n",
            "Target Text: Ẹ káàsán, sà.\n",
            "Predicted by YorubaGPT: Ẹ káàsán , sà .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 58: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.075]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa, ẹ fún mi ní aláàádọ́ta náírà.\n",
            "Target Text: Ó dáa.\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ fi ṣúgà sí i dáadáa.\n",
            "Target Text: Mi ò kí í po tíì láì sí ṣúgà.\n",
            "Predicted by YorubaGPT: Mi ò kí í po tíì lá ì sí ṣúgà .\n",
            "BLEU score: 0.2399\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 59: 100%|██████████| 222/222 [00:31<00:00,  7.05it/s, loss=1.067]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa.\n",
            "Target Text: Ó dàbọ̀.\n",
            "Predicted by YorubaGPT: Ó dàbọ̀ .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni jálẹ̀jálẹ̀?\n",
            "Target Text: Jálẹ̀jálẹ̀ nì yẹn.\n",
            "Predicted by YorubaGPT: Ọ̀gá , iye ẹ̀ nì yẹn .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 60: 100%|██████████| 222/222 [00:31<00:00,  6.95it/s, loss=1.559]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Àwọn rèé:  orí màlúù kan, awọ, ẹsẹ̀, àti orí àgbò.\n",
            "Target Text: orí màlúù kan, ẹsẹ̀ mẹ́rin, ìrù màlúù àti orí àgbò márùn-ún.\n",
            "Predicted by YorubaGPT: orí màlúù kan , ẹsẹ̀ mẹ́rin , ì rù màlúù àti orí àgbò márùn - ún .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa. Ẹ seun. Owó rèé!\n",
            "Target Text: Ẹ seun o. \n",
            "Predicted by YorubaGPT: Ó dàbọ̀ .\n",
            "BLEU score: 0.0885\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 61: 100%|██████████| 222/222 [00:31<00:00,  7.05it/s, loss=1.121]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Á hàá, ṣé iye tí ẹ fẹ́ẹ́ tà á nì yẹn?\n",
            "Target Text: Ọgọ́rùn-ún méjì àti àádọ́ta náírà ni jálẹ̀jálẹ̀.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún méjì àti àádọ́ta náírà ni jálẹ̀jálẹ̀ .\n",
            "-------------------------------------------------------\n",
            "Source Text: Màá san ọgbọ̀n náírà.\n",
            "Target Text: Ẹ san ogójì náírà.\n",
            "Predicted by YorubaGPT: Ẹ san ogójì náírà .\n",
            "BLEU score: 0.1964\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 62: 100%|██████████| 222/222 [00:31<00:00,  7.05it/s, loss=1.114]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Hajiya, ẹran eélòó ni ẹ fẹ́ rà?\n",
            "Target Text: Ọgọ́rùn-ún márùn-ún náírà..\n",
            "Predicted by YorubaGPT: Kò ṣ òro rárá láti dé Ọ̀ fà . Ọ̀ kan lá ra àwọn Ìdíkọ̀ wa tí ó gba jú gba jà ni Ọ̀ fà . Bí ọkọ̀ ojúurin bá ti gbéra ní Èkó , á dúró ní A b ẹ́ ò kú ta , Ì bà d àn àti Ò ṣ o gbo , ó di Ọ̀ f fà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa. Ẹ seun.\n",
            "Target Text: A dúpẹ́\n",
            "Predicted by YorubaGPT: Ó dàbọ̀ .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 63: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.760]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ṣùgbọ́n, ẹ lè gbàgbé àti fi ṣúgà sí i..\n",
            "Target Text: Ó dáa, màá bá ẹ fi ṣúgà sí i dáadáa.\n",
            "Predicted by YorubaGPT: Ó dáa , màá bá ẹ fi ṣúgà sí i dáadáa .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ọgọ́fà náírà, ní ìgbà òjò yí?\n",
            "Target Text: Bẹ́ẹ̀ni, ọgọ́fà náírà ni. Ṣé kí n dì í?\n",
            "Predicted by YorubaGPT: Kò dín rárá . Iye tí à ń s ún wọ́n nì yẹn .\n",
            "BLEU score: 0.2666\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 64: 100%|██████████| 222/222 [00:31<00:00,  7.06it/s, loss=1.125]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni gúábà?\n",
            "Target Text: Èyí ọọ́rùn-ún náírà, ìyẹn ọgọ́ta.\n",
            "Predicted by YorubaGPT: Èyí ọ ọ́ rùn - ún náírà , ìyẹn ọgọ́ta\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹhn.\n",
            "Target Text: Ṣàkì àti ‘roundabout’ ńkọ́?\n",
            "Predicted by YorubaGPT: Ṣ à kì àti ‘ roun da bo u t ’ ńkọ́ ?\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 65: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.105]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni àbùfọ̀ Ariel?\n",
            "Target Text: Ńlá tàbí kékeré?\n",
            "Predicted by YorubaGPT: Ń lá tàbí kékeré ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ jẹ́ kí a san ogọ́rùn-ún márùn-ún àti àádọ́ta náírà (N550).ọgọ́rùn-ún náírà, àwa náà a lè jẹ èrè àádọ́ta náírà.\n",
            "Target Text: Àpò mélòó ni ẹ fẹ́?\n",
            "Predicted by YorubaGPT: Ó tì .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 66: 100%|██████████| 222/222 [00:31<00:00,  7.06it/s, loss=1.116]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ọ̀rá Santana tí wọ́n ń pè ní ‘Abiola’?\n",
            "Target Text: Soji ni àwa ń pè é níbí. Ọgọ́rin náírà péré ni.\n",
            "Predicted by YorubaGPT: S o ji ni àwa ń pè é ní bí . Ọgọ́ rin náírà péré ni .\n",
            "-------------------------------------------------------\n",
            "Source Text: Mo fẹ́ kí ẹ bá mi sún àwọn nǹkan kan ni\n",
            "Target Text: Àwọn nǹkan wo?\n",
            "Predicted by YorubaGPT: Àwọn nǹkan wo ?\n",
            "BLEU score: 0.1231\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 67: 100%|██████████| 222/222 [00:31<00:00,  7.07it/s, loss=1.074]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa. Ẹ seun. Owó rèé!\n",
            "Target Text: Ẹ seun o. \n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣùgbọ́n, ẹ lè gbàgbé àti fi ṣúgà sí i..\n",
            "Target Text: Ó dáa, màá bá ẹ fi ṣúgà sí i dáadáa.\n",
            "Predicted by YorubaGPT: Ó dáa , màá bá ẹ fi ṣúgà sí i dáadáa .\n",
            "BLEU score: 0.2666\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 68: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.086]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ dì í pọ̀ bí ẹ ṣe máa ń ṣe é.\n",
            "Target Text: Ó dáa.\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣé ajé ń wọgbá?\n",
            "Target Text: A dúpẹ́ lọ́wọ́ Ọlọ́run.\n",
            "Predicted by YorubaGPT: A dúpẹ́ lọ́wọ́ Ọlọ́run .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 69: 100%|██████████| 222/222 [00:31<00:00,  7.05it/s, loss=1.509]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa. Ṣé màá rí wọn gbà lónìí?\n",
            "Target Text: Lágbára Ọlọ́run. Wọn ò nó pẹ́ ẹ́ ṣe tán\n",
            "Predicted by YorubaGPT: Lá gbá ra Ọlọ́run . W ọn ò n ó pẹ́ ẹ́ ṣe tán\n",
            "-------------------------------------------------------\n",
            "Source Text: Ọlọ́run á sọ òde dẹ̀rọ̀. Ẹ mún ún wá bẹ́ẹ̀.\n",
            "Target Text: Òhun rè é!\n",
            "Predicted by YorubaGPT: Ò hun rè é !\n",
            "BLEU score: 0.0940\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 70: 100%|██████████| 222/222 [00:31<00:00,  7.00it/s, loss=1.108]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Bẹ́ẹ̀ni.\n",
            "Target Text: Kí ni ẹ tún fẹ́?\n",
            "Predicted by YorubaGPT: N220 .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣé èyí ni wọ́n ń tà ní ẹgbẹ̀rún kan àti ọgọ́rùn-ún mẹ́ta náírà?\n",
            "Target Text: Bẹ́ẹ̀ni, ẹgbẹ̀rún kan àti ọgọ́rùn-ún mẹ́ta náírà ni.\n",
            "Predicted by YorubaGPT: Bẹ́ẹ̀ni\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 71: 100%|██████████| 222/222 [00:31<00:00,  7.01it/s, loss=1.051]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni jálẹ̀jálẹ̀?\n",
            "Target Text: Bẹ́ẹ́ni, ọgọ́rùn-ún méjì àti àádọ́ta náírà ni.\n",
            "Predicted by YorubaGPT: Jálẹ̀jálẹ̀ nì yẹn .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹhn.\n",
            "Target Text: Ṣàkì àti ‘roundabout’ ńkọ́?\n",
            "Predicted by YorubaGPT: Ṣ à kì àti ‘ roun da bo u t ’ ńkọ́ ?\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 72: 100%|██████████| 222/222 [00:31<00:00,  7.02it/s, loss=1.064]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ jọ̀ọ́, mò ń kánjú. Àwọn ọmọ mi ń lọ sí ilé-ìwé láì pẹ́.\n",
            "Target Text: Bí ẹ ṣe ń ná an, èmi gan-an ò rí i rà bẹ́ẹ̀, ká má ì tíì sọ ti èrè.\n",
            "Predicted by YorubaGPT: Bí ẹ ṣe ń ná an , è mi gan - an ò rí i rà bẹ́ẹ̀ , ká má ì tíì sọ ti èrè .\n",
            "-------------------------------------------------------\n",
            "Source Text: Á hàá, ṣé iye tí ẹ fẹ́ẹ́ tà á nì yẹn?\n",
            "Target Text: Ọgọ́rùn-ún méjì àti àádọ́ta náírà ni jálẹ̀jálẹ̀.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún méjì àti àádọ́ta náírà ni jálẹ̀jálẹ̀ .\n",
            "BLEU score: 0.3993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 73: 100%|██████████| 222/222 [00:31<00:00,  7.02it/s, loss=1.074]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa, ẹ pò ó!\n",
            "Target Text: Ó dáa.\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ kú iṣẹ́ o.\n",
            "Target Text: Ẹ kú àbọ̀ .\n",
            "Predicted by YorubaGPT: Ẹ kú àbọ̀ .\n",
            "BLEU score: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 74: 100%|██████████| 222/222 [00:31<00:00,  7.06it/s, loss=1.090]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ọgọ́fà náírà, ní ìgbà òjò yí?\n",
            "Target Text: Bẹ́ẹ̀ni, ọgọ́fà náírà ni. Ṣé kí n dì í?\n",
            "Predicted by YorubaGPT: Kò kúkú sí . Mo kàn fẹ́ kí wọ́n mọ̀ ọjà ní ná ni , kán sì mọ̀ pé ṣe ni à ń ṣiṣẹ́ ká ra ká tó r ó wó .\n",
            "-------------------------------------------------------\n",
            "Source Text: Àpò kan péré ni.\n",
            "Target Text: Ẹ san owó!\n",
            "Predicted by YorubaGPT: Ọkọ̀ ti kún o . Gbogbo èrò , ẹ wọlé , kí ẹ sanwó ọkọ̀ . Ọkọ̀ kò ní í pẹ́ ṣ í .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 75: 100%|██████████| 222/222 [00:31<00:00,  7.00it/s, loss=1.135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ fún mi ní àgbọn ogún náírà àti date ogún náírà.\n",
            "Target Text: Ó dáa. Òun rèé!\n",
            "Predicted by YorubaGPT: Ó dáa . Òun rèé !\n",
            "-------------------------------------------------------\n",
            "Source Text: Bá wo ni gbogbo nǹka?\n",
            "Target Text: A dúpẹ́ lọ́wọ́ Ọlọ́run.\n",
            "Predicted by YorubaGPT: Iṣẹ́ ńkọ́ ?\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 76: 100%|██████████| 222/222 [00:31<00:00,  7.09it/s, loss=1.132]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹhn.\n",
            "Target Text: Ṣàkì àti ‘roundabout’ ńkọ́?\n",
            "Predicted by YorubaGPT: Ṣ à kì àti ‘ roun da bo u t ’ ńkọ́ ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ẹ ń ta?\n",
            "Target Text: Èyí àádọ́ta náírà, èyí ọgbọ̀n náírà.\n",
            "Predicted by YorubaGPT: Èyí àádọ́ta náírà , èyí ọgbọ̀n náírà .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 77: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=1.103]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa, eélòó ni jálẹ̀jálẹ̀?\n",
            "Target Text: Ẹgbẹ̀rún kan-àbọ̀ náírà ni à ń tà á.\n",
            "Predicted by YorubaGPT: Ẹgbẹ̀rún kan - àbọ̀ náírà ni à ń tà á .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ gba Ẹgbẹ̀rún ó lé àádọ́rin naira\n",
            "Target Text: Ó ku Ọgọ́rùn-ún márùn-ún náírà (N500).\n",
            "Predicted by YorubaGPT: Ó ku Ọgọ́rùn - ún márùn - ún náírà\n",
            "BLEU score: 0.1836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 78: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=1.084]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ mú u wá!\n",
            "Target Text: Mélòó?\n",
            "Predicted by YorubaGPT: M élòó ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣé wọ́n pọ́n báyìí?\n",
            "Target Text: Gbogbo wọn ló pọ́n.\n",
            "Predicted by YorubaGPT: Gbogbo wọn ló p ọ́n .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 79: 100%|██████████| 222/222 [00:31<00:00,  6.98it/s, loss=1.059]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Alánàmá, eélòó ni ànàmá?\n",
            "Target Text: Ọgọ́rùn-ún méjì náírà ni èyí.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún méjì náírà ni èyí .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa.\n",
            "Target Text: Ẹ ǹlẹ́\n",
            "Predicted by YorubaGPT: Ó dàbọ̀ .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 80: 100%|██████████| 222/222 [00:31<00:00,  7.05it/s, loss=1.098]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ẹ ń ta?\n",
            "Target Text: Èyí àádọ́ta náírà, èyí ọgbọ̀n náírà.\n",
            "Predicted by YorubaGPT: Èyí àádọ́ta náírà , èyí ọgbọ̀n náírà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Bẹ́ẹ̀ni.\n",
            "Target Text: Kí ni ẹ tún fẹ́?\n",
            "Predicted by YorubaGPT: Kilo mélòó ?\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 81: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.110]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Bá wo ni ẹ ṣe ń tà á?\n",
            "Target Text: Bí ẹ bá ṣe fẹ́ ẹ sí ni. A ń ta oní- àádọ́ta náírà ogójì náírà àti ọgbọ̀n náírà.\n",
            "Predicted by YorubaGPT: Bí ẹ bá ṣe fẹ́ ẹ sí ni . A ń ta oní - àádọ́ta náírà ogójì náírà àti ọgbọ̀n náírà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Àádọ́ta náírà ti pọ̀ jù.\n",
            "Target Text: Ó ti wọ́n sí ni.\n",
            "Predicted by YorubaGPT: Ó ti wọ́n sí ni .\n",
            "BLEU score: 0.5224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 82: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=1.061]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ńlá.\n",
            "Target Text: Ọgọ́rùn-ún mẹ́rin náírà ni ńlá.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún mẹ́rin náírà ni ń lá .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó dàbọ̀.\n",
            "Target Text: Ẹ seun.\n",
            "Predicted by YorubaGPT: Ó dàbọ̀ .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 83: 100%|██████████| 222/222 [00:31<00:00,  7.05it/s, loss=1.056]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eléyìí ńkọ́?\n",
            "Target Text: Ọgọ́rùn-ún náírà.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún náírà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa, ẹ fún mi ní kóńgò méjì!\n",
            "Target Text: Ó dáa.\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 84: 100%|██████████| 222/222 [00:31<00:00,  7.03it/s, loss=1.110]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ǹjẹ́ ẹ ni orógbó?\n",
            "Target Text: Ó wà. Ẹ gbà!\n",
            "Predicted by YorubaGPT: Ó wà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa.\n",
            "Target Text: Ẹ ǹlẹ́\n",
            "Predicted by YorubaGPT: Ó dàbọ̀ .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 85: 100%|██████████| 222/222 [00:31<00:00,  7.04it/s, loss=1.246]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni àpò yí?\n",
            "Target Text: Ẹgbẹ̀rún kan-àbọ̀ náírà ni àpò.\n",
            "Predicted by YorubaGPT: Ẹgbẹ̀rún kan - àbọ̀ náírà ni àpò .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ṣé ẹ ò fẹ́ kí a di oníbàárà ni?\n",
            "Target Text: Kò rí bẹ́ẹ̀. Nǹkan ló wọ́n.\n",
            "Predicted by YorubaGPT: Kò rí bẹ́ẹ̀ . N ǹkan ló wọ́n .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 86: 100%|██████████| 222/222 [00:31<00:00,  7.00it/s, loss=1.050]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ṣé wọ́n pọ́n báyìí?\n",
            "Target Text: Gbogbo wọn ló pọ́n.\n",
            "Predicted by YorubaGPT: Gbogbo wọn ló p ọ́n .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa, ẹ fún mi ní kóńgò méjì!\n",
            "Target Text: Ó dáa.\n",
            "Predicted by YorubaGPT: Ó dáa .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 87: 100%|██████████| 222/222 [00:31<00:00,  7.09it/s, loss=1.086]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Maggi oníràwọ̀ àti “Mr. Chef”. Ǹjẹ́ ẹ ni ọṣẹ Septol?\n",
            "Target Text: Septol wà.\n",
            "Predicted by YorubaGPT: S e p to l wà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó tì.\n",
            "Target Text: Ẹ gbà. Ẹ seun o. Ó dàbọ̀.\n",
            "Predicted by YorubaGPT: Ẹ gbà . Ẹ seun o . Ó dàbọ̀ .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 88: 100%|██████████| 222/222 [00:31<00:00,  7.15it/s, loss=1.064]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Àádọ́ta náírà ti pọ̀ jù.\n",
            "Target Text: Ó ti wọ́n sí ni.\n",
            "Predicted by YorubaGPT: Ó ti wọ́n sí ni .\n",
            "-------------------------------------------------------\n",
            "Source Text: Mo fẹ́ “Lipton” àti mílíìkì, àti blueband.\n",
            "Target Text: Pẹ̀lú bọ̀tà?\n",
            "Predicted by YorubaGPT: Pẹ̀ lú bọ̀ tà ?\n",
            "BLEU score: 0.2541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 89: 100%|██████████| 222/222 [00:31<00:00,  7.11it/s, loss=1.076]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ tà á fún mi bẹ́ẹ̀, ṣe bí oníbàárà yín ni mí.\n",
            "Target Text: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀?\n",
            "Predicted by YorubaGPT: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀ ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ ǹlẹ́ o, Ọ̀gá.\n",
            "Target Text: Ẹ káàsán, sà.\n",
            "Predicted by YorubaGPT: Ẹ káàsán , sà .\n",
            "BLEU score: 0.3402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 90: 100%|██████████| 222/222 [00:30<00:00,  7.18it/s, loss=1.058]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Mo fẹ́ ra Magi.\n",
            "Target Text: Maggi nìkan?\n",
            "Predicted by YorubaGPT: Ma g g g i nìkan ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni jálẹ̀jálẹ̀?\n",
            "Target Text: Ogójì náírà.\n",
            "Predicted by YorubaGPT: Jálẹ̀jálẹ̀ nì yẹn .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 91: 100%|██████████| 222/222 [00:30<00:00,  7.23it/s, loss=1.057]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni jálẹ̀jálẹ̀?\n",
            "Target Text: Bẹ́ẹ́ni, ọgọ́rùn-ún méjì àti àádọ́ta náírà ni.\n",
            "Predicted by YorubaGPT: Jálẹ̀jálẹ̀ nì yẹn .\n",
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni jálẹ̀jálẹ̀?\n",
            "Target Text: Àádọ́rin náírà ni jálẹ̀jálẹ̀.\n",
            "Predicted by YorubaGPT: Jálẹ̀jálẹ̀ nì yẹn .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 92: 100%|██████████| 222/222 [00:29<00:00,  7.41it/s, loss=1.094]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni gbogbo ẹ̀?\n",
            "Target Text: Gbogbo ẹ̀ jẹ́ ọgọ́rùn-ún méjì àti ọgọ́rin náírà.\n",
            "Predicted by YorubaGPT: Gbogbo ẹ̀ jẹ́ ọgọ́rùn - ún méjì àti ọgọ́ rin náírà .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ fi ṣúgà sí i dáadáa.\n",
            "Target Text: Mi ò kí í po tíì láì sí ṣúgà.\n",
            "Predicted by YorubaGPT: Mi ò kí í po tíì lá ì sí ṣúgà .\n",
            "BLEU score: 0.2399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 93: 100%|██████████| 222/222 [00:30<00:00,  7.32it/s, loss=1.064]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ẹ fi í sílẹ̀ fún mi bẹ́ẹ̀.\n",
            "Target Text: Ẹ jọ̀ọ́, mi ò lè tà á bẹ́ẹ̀.\n",
            "Predicted by YorubaGPT: Ẹ jọ̀ọ́ , mi ò lè tà á bẹ́ẹ̀ .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ mú u wá!\n",
            "Target Text: Mélòó?\n",
            "Predicted by YorubaGPT: M élòó ?\n",
            "BLEU score: 0.2056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 94: 100%|██████████| 222/222 [00:30<00:00,  7.29it/s, loss=1.049]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Onígbàá, ṣé ajé ń wọgbá?\n",
            "Target Text: A dúpẹ́.\n",
            "Predicted by YorubaGPT: A dúpẹ́ lọ́wọ́ Ọlọ́run .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa, ẹ fún mi ní kóńgò méjì sóbò.\n",
            "Target Text: Àwọn eléyìí ńkọ́, mélòó ni kí n fi si?\n",
            "Predicted by YorubaGPT: Àwọn eléyìí ńkọ́ , mélòó ni kí n fi si ?\n",
            "BLEU score: 0.2018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 95: 100%|██████████| 222/222 [00:30<00:00,  7.26it/s, loss=1.087]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Eélòó ni ẹ máa tà á jálẹ̀jálẹ̀?\n",
            "Target Text: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀?\n",
            "Predicted by YorubaGPT: Eélòó ni ẹ máa rà á jálẹ̀jálẹ̀ ?\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa. Ṣé màá rí wọn gbà lónìí?\n",
            "Target Text: Lágbára Ọlọ́run. Wọn ò nó pẹ́ ẹ́ ṣe tán\n",
            "Predicted by YorubaGPT: Lá gbá ra Ọlọ́run . W ọn ò n ó pẹ́ ẹ́ ṣe tán\n",
            "BLEU score: 0.4342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 96: 100%|██████████| 222/222 [00:30<00:00,  7.24it/s, loss=1.073]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Àpò kan péré ni.\n",
            "Target Text: Ẹ san owó!\n",
            "Predicted by YorubaGPT: Ọkọ̀ ti kún o . Gbogbo èrò , ẹ wọlé , kí ẹ sanwó ọkọ̀ . Ọkọ̀ kò ní í pẹ́ ṣ í .\n",
            "-------------------------------------------------------\n",
            "Source Text: Alánàmá, eélòó ni ànàmá?\n",
            "Target Text: Ọgọ́rùn-ún méjì náírà ni èyí.\n",
            "Predicted by YorubaGPT: Ọgọ́rùn - ún méjì náírà ni èyí .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 97: 100%|██████████| 222/222 [00:30<00:00,  7.22it/s, loss=1.112]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ọgọ́fà náírà, ní ìgbà òjò yí?\n",
            "Target Text: Bẹ́ẹ̀ni, ọgọ́fà náírà ni. Ṣé kí n dì í?\n",
            "Predicted by YorubaGPT: Kò burú . Ẹ sanwó .\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó dáa.\n",
            "Target Text: Ó dàbọ̀.\n",
            "Predicted by YorubaGPT: Ó dàbọ̀ .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 98: 100%|██████████| 222/222 [00:30<00:00,  7.21it/s, loss=1.156]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Alhaji, ṣé ajé ń wọgbá?\n",
            "Target Text: A dúpẹ́\n",
            "Predicted by YorubaGPT: A dúpẹ́\n",
            "-------------------------------------------------------\n",
            "Source Text: Ẹ fún mi ní àgbọn ogún náírà àti date ogún náírà.\n",
            "Target Text: Ó dáa. Òun rèé!\n",
            "Predicted by YorubaGPT: Ó dáa . Òun rèé !\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 99: 100%|██████████| 222/222 [00:30<00:00,  7.23it/s, loss=1.086]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ọlọ́run á sọ òde dẹ̀rọ̀. Ẹ mún ún wá bẹ́ẹ̀.\n",
            "Target Text: Òhun rè é!\n",
            "Predicted by YorubaGPT: Ò hun rè é !\n",
            "-------------------------------------------------------\n",
            "Source Text: Ó tì.\n",
            "Target Text: Ẹ gbà. Ẹ seun o. Ó dàbọ̀.\n",
            "Predicted by YorubaGPT: Ẹ gbà . Ẹ seun o . Ó dàbọ̀ .\n",
            "BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "[enforce fail at inline_container.cc:595] . unexpected pos 142605376 vs 142605264",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_byteorder_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:764] . PytorchStreamWriter failed writing file data/243: file write failed",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-17d46ec61db0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreload_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-257e664adadb>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(preload_epoch)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Save the model at the end of every epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mmodel_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"./Yorubagpt/model_{epoch}.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         torch.save({\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_byteorder_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:595] . unexpected pos 142605376 vs 142605264"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NDqivXbV4pjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4G993CS8YZWx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}